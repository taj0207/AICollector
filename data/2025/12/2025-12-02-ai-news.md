# AI News for 2025-12-02 (America/Los_Angeles)

Collected 18 article(s).

- [Data & AI-driven management - Fujitsu Global](https://news.google.com/rss/articles/CBMiaEFVX3lxTE5qTzJfV05YRHBZaHc2RUgwdTVXUTh3TzhjZ284bHNvUEo2NFlXS0lJaXdTN1Zob2JQcjU5VEh3YjVFNDN5TGdxdVhVbDZ2T0QtWWlFSkFtNU1COTVUQ2hzU3Q2eUFqZkNM?oc=5) — 21:11 · Google News (AI)
  > Data & AI-driven management  Fujitsu Global
- [We Need States’ Innovations on AI Regulation. Don’t Shut Them Down. - Governing](https://news.google.com/rss/articles/CBMinAFBVV95cUxPZ1RlbDlDVW1sQ1M3aC1BSzlmcnlTbXBYcXRYSjlHZE1YVVFWQXM5bWtyY09KQTdGQS1wbzlXNVE5WW9SQUR2Y3J1T1l0c2FEMEZBTTlfdWVrbmF2MDczbW9WR1VHeS1uT0VrdnM4Nng3Q01CeGZoSGpTS21Pd1U5TTRNYWl4b29lZjN1RExQWmVyc3k5RUpNaFVwUHU?oc=5) — 21:03 · Google News (AI)
  > We Need States’ Innovations on AI Regulation. Don’t Shut Them Down.  Governing
- [The hunt for copper to wire the AI boom - Financial Times](https://news.google.com/rss/articles/CBMicEFVX3lxTFA1bTV2QnVGdWhmOFBFQ2VhOFlBcm5uSGFiQkM3Tnl6TVlNR2ZNMFlfRWNNRHhjNzhvcVYzTlhTVFBtaVBlQ3RXSlhZa3gwXzV5VGZtOUhGVkRRRWVBOXpkTmlsZWVvSm5XN2R0TW5zUTc?oc=5) — 21:00 · Google News (AI)
  > The hunt for copper to wire the AI boom  Financial Times
- [AI has redefined the talent game. Here’s how leaders are responding.](https://venturebeat.com/ai/ai-has-redefined-the-talent-game-heres-how-leaders-are-responding) — 21:00 · VentureBeat AI
  > Presented by IndeedAs AI continues to reshape how we work, organizations are rethinking what skills they need, how they hire, and how they retain talent. According to Indeed’s 2025 Tech Talent report, tech job postings are still down more than 30% from pre-pandemic highs, yet demand for AI expertise has never been greater. New roles are emerging almost overnight, from prompt engineers to AI operations managers, and leaders are under growing pressure to close skill gaps while supporting their teams through change. Shibani Ahuja, SVP of enterprise IT strategy at Salesforce; Matt Candy, global managing partner of generative AI strategy and transformation at IBM; and Jessica Hardeman, global head of attraction and engagement at Indeed came together for a recent roundtable conversation about the future of tech talent strategy, from hiring and reskilling to how it's reshaping the workforce.Strategies for sourcing talentTo find the right candidates, organizations need to be certain their communication is clear from the get-go, and that means beginning with a well-thought-out job description, Hardeman said. "How clearly are you outlining the skills that are actually required for the role, versus using very high-level or ambiguous language," she said. "Something that I also highly recommend is skill-cluster sourcing. We use that to identify candidates that might be adjacent to these harder-to-find niche skills. That’s something we can upskill people into. For example, skills that are in distributed computing or machine learning frameworks also share other high-value capabilities. Using these clusters can help recruiters identify candidates that may not have that exact skill set you’re looking for, but can quickly upskill into it."Recruiters should also be upskilled, able to spot that potential in candidates. And once they're hired, companies have to be intentional about how they’re growing talent from the day they step in the door. "What that means in the near term is focusing on the mentorship, embedding that AI fluency into their onboarding experience, into their growth, into their development," she said. "That means offering upskilling that teaches not just the tools they’ll need, but how to think with those tools and alongside those. The new early career sweet spot is where technical skills meet our human strengths. Curiosity. Communication. Data judgment. Workflow design. Those are the things that AI cannot replicate or replace. We have to create mentorship and sponsorship opportunities. Well-being and culture are critical components to ensuring that we’re creating good places for that early-in-career talent to land."How work will evolve along AIAs AI becomes embedded into daily technical work, organizations are rethinking what it means to be a developer, designer, or engineer. Instead of automating roles end to end, companies are increasingly building AI agents that act as teammates, supporting workers across the entire software development lifecycle.Candy explained that IBM is already seeing this shift in action through its Consulting Advantage platform, which serves as a unified AI experience layer for consultants and technical teams.“This is a platform that every one of our consultants works with,” he said. “It’s supported by every piece of AI technology and model out there. It’s the place where our consultants can access thousands of agents that help them in each job role and activity they’re doing.”These aren’t just prebuilt tools — teams can create and publish their own agents into an internal marketplace. That has sparked a systematic effort to map every task across traditional tech roles and build agents to enhance them.“If I think about your traditional designer, DevOps engineer, AI Ops engineer — what are all the different agents that are supporting them in those activities?” Candy said. “It’s far more than just coding. Tools like Cursor, Windsurf, and GitHub Copilot accelerate coding, but that’s only one part of delivering software end to end. We’re building agents to support people at every stage of that journey.”Candy said this shift leads toward a workplace where AI becomes a collaborative partner rather than a replacement, something that enables tech workers to spend more time on creative, strategic, and human-centered tasks."This future where employees have agents working alongside them, taking care of some of these repetitive activities, focusing on higher-value strategic work where human skills are innately important, I think becomes right at the heart of that,” he explained. “You have to unleash the organization to be able to think and rethink in that way."A lot of that depends on the mindset of company leaders, Ahuja said. "I can see the difference between leaders that look at AI as cost-cutting, reduction — it’s a bottom-line activity,” she said. “And then there are organizations that are starting to shift their mindset to say, no, the goal is not about replacing people. It’s about reimagining the work to make us humans more human, ironically. For some leaders that’s the story their PR teams have told them to say. But for those that actually believe that AI is about helping us become more human, it’s interesting how they’re bringing that to life and bridging this gap between humanity and digital labor." Shifting the culture toward AIThe companies that are most successful at navigating the obstacles around successful AI implementation and culture change make employees their first priority, Ahuja added. They prioritize use cases that solve the most boring problems that are burdening their teams, demonstrating how AI will help, as opposed to looking at what the maximum number of jobs automation can replace."They’re thinking of it as preserving human accountability, so in high-stakes moments, people will still make that final call," she said. "Looking at where AI is going to excel at scale and speed with pattern recognition, leaving that space for humans to bring their judgement, their ethics, and their emotional intelligence. It seems like a very subtle shift, but it’s pretty big in terms of where it starts at the beginning of an organization and how it trickles down."It's also important to build a level of comfort in using AI in employees’ day-to-day work. Salesforce created a Slack chat called Bite-Sized AI in which they encourage every colleague, including company leaders, to talk about where they're using AI and why, and what hacks they've found. "That’s creating a safe space," Ahuja explained. "It’s creating that psychological safety — that this isn’t just a buzzword. We’re trying to encourage it through behavior.""This is all about how you ignite, especially in big enterprises, the kind of passion and fire inside everyone’s belly," Candy added. "Storytelling, showing examples of what great looks like. The expression is 'demos, not memos'. Stop writing PowerPoint slides explaining what we're going to do and actually getting into the tools to show it in real life.”AI makes that continuous learning a non-negotiable, Hardeman added, with companies training employees in understanding how to use the AI tools they're provided, and that goes a long way toward building that AI culture. "We view upskilling as a retention lever and a performance driver," she said. "It creates that confidence, it reduces the fear around AI adoption. It helps people see a future for themselves as the technology evolves. AI didn’t just raise the bar on skills. It raised the bar on how we’re trying to support our people. It’s important that we are also rising to that occasion, and we’re not just raising expectations on the folks that we work with."Sponsored articles are content produced by a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact sales@venturebeat.com.
- [Chronquiry: Why do students actually use generative AI? - The Duke Chronicle](https://news.google.com/rss/articles/CBMi8gFBVV95cUxQeUdRbHlBSGxmTldUUFcxV1Z0MElVLUdEOWtPZTNxcGtQX0FzN2dWc2s4MXpPUVhjMERLLVhTZ0ZndkN4UDFOSHc1d1BDVDFKc3JxVjNSUHVKWU9YZ2hCMl9reG05eVM2REswdHBJWU8tREtQT0FENlFHcWh2Ujd5TGJJQkZZVlJvTjdKT2hqYUpLQ1NoeTVMMHljU19WbFRQdlg3MXRIS052dDRWSGIwMXU4NDlreTR5a3o1WHNwckpteW1xUDRYaDdFOTFiT1RsYnY4eUdDUWlaRjJENXBRR0RCWGF0QV96T2JzanBBcTVMUQ?oc=5) — 20:26 · Google News (AI)
  > Chronquiry: Why do students actually use generative AI?  The Duke Chronicle
- [Creativity is threatened by lack of restrictions on AI - The Baylor Lariat](https://news.google.com/rss/articles/CBMilgFBVV95cUxQVkVmN1RzZFRpdU5sdTl2bW9rcjlzcDJHMUJaNy1feW1YMTFQcE5lWUxMZHZQTkRNTG5LbFZwUVNIUEgxbmx0bFozdmFnYlFNWGNCSXI1Q1NyYjM0TUF4N0dhdWpMb21MNFFwLWhGMnJKbVY0aUl6cjhEODEwMl9FMkJDenpsQzMwTENDZTUySkowMnM1QnfSAZ4BQVVfeXFMUFk5bWVpR2toWkFDLTRBd2dLZVljc2xLVVhIVWR6amZaQWw3UXJ1X0VnS3VSUDlyZUZNYjJENWdSbHMwMndCS0dtSnl0S0JvbUxIb2ZESWlVTl85NDZfaE1YdlNHcWhvbjkxNGgwaldrZmxJU1BfWmUzcTJ3X0pSb2hMem5KcWZyZ0pRYjh4SF9EcUVhcWJKclR6LV9kNmc?oc=5) — 20:21 · Google News (AI)
  > Creativity is threatened by lack of restrictions on AI  The Baylor Lariat
- [The AI frenzy is driving a memory chip supply crisis - Reuters](https://news.google.com/rss/articles/CBMioAFBVV95cUxPb24zbTlISHhiN3MwUFFvYWVSaGNpeUx0NFNEODR0eldqZHV0YnZQSFhPZFhsOGFlaDJTR1h4Y3FOdjdlWnBhQXc2VjdrbG9xSHVqMzdib1I0WFJBTkY2QWNUMTVQNkMwRUNpSkV0MldVUTd0NzczWWJJWVg2T0pmRHQzUjc1a0Z2cGVvaGJvdHFlQ19EdmJJOF9XRWFLd2xY?oc=5) — 19:15 · Google News (AI)
  > The AI frenzy is driving a memory chip supply crisis  Reuters
- [Marvell to buy chip startup Celestial AI for $3.25 billion, bullish on growth next year - Reuters](https://news.google.com/rss/articles/CBMiswFBVV95cUxNbGdDb1pzQTdrcTRHSVhyRVlEQ3FhSXBKVFVrQzJZdERSNFlnNGZTc0dMb2xleVVfcnVRdzJYcHNJN2tvcGFpUnh1V2VjeWV2Q09ybG1kWTNCbzhaSUxaNUY1bl9nWG1NdklMeC1sRnRVenZaS2tNdnhwT3lTOG4wbUxmRHR4aGJlTmJTYTQ3bFI0WE55c0FobVZLWmhLOURkdjlyQnd0TkRSOUFabzlDdWJLNA?oc=5) — 15:32 · Google News (AI)
  > Marvell to buy chip startup Celestial AI for $3.25 billion, bullish on growth next year  Reuters
- [Indiegogo is launching ‘Express Crowdfunding’ so creators can ship things sooner](https://www.theverge.com/news/836886/indiegogo-express-crowdfunding-ayaneo-shipping) — 14:24 · The Verge (AI)
  > Indiegogo is planning to launch a new “Express Crowdfunding” campaign format that lets creators ship things while the campaign is ongoing instead of forcing creators to wait until the campaign is over. Indiegogo spokesperson Maciej Kuc tells The Verge that the change was spurred by Indiegogo’s recent move to the infrastructure from its new owner, […]
- [Google is experimentally replacing news headlines with AI clickbait nonsense](https://www.theverge.com/ai-artificial-intelligence/835839/google-discover-ai-headlines-clickbait-nonsense) — 14:14 · The Verge (AI)
  > Did you know that BG3 players exploit children? Are you aware that Qi2 slows older Pixels? If we wrote those misleading headlines, readers would rip us a new one - but Google is experimentally beginning to replace the original headlines on stories it serves with AI nonsense like that. I read a lot of my […]
- [To AI or not to AI? Do college students appreciate the question? - NPR](https://news.google.com/rss/articles/CBMiqwFBVV95cUxQSGozRU83aWNCZE1EbVBxRXBIWVAyUTRNczFMMms1NnNVUHlkSlpRNE1OVjBkZ21DM2JtT3hnSGszWkRtSXN4dTBwSHhfTU9RbjNwQ3JlWFRDUWtBZWZSTjh1Zmc2Sl9JZTVJdG45OGoxMUtNRnI1cHRRQW8wZElIX2FxemJUN3otcDJOc0VsWHRlMzItTjdtdmlSSk9WNU1JNk1NVlVSM0dsc1U?oc=5) — 14:04 · Google News (AI)
  > To AI or not to AI? Do college students appreciate the question?  NPR
- [How AI Is Transforming Work at Anthropic - Anthropic](https://news.google.com/rss/articles/CBMigAFBVV95cUxQZFBSaEZtOG1ieHpOdldrNVJEeGRCMEtJVmpNU1hOMHVNV1NldWJ1T3RuQlhTZXpkckk2akpUWFhqbGtabXRURFJiNDR4aG9YUjhUSzFadkZaYUJPNElQcDR4SkU2bHIyQkg3VDdmMWZ0eFM5ak52MThpcklEdVNfVg?oc=5) — 11:22 · Google News (AI)
  > How AI Is Transforming Work at Anthropic  Anthropic
- [Amazon's new AI can code for days without human help. What does that mean for software engineers?](https://venturebeat.com/ai/amazons-new-ai-can-code-for-days-without-human-help-what-does-that-mean-for) — 09:30 · VentureBeat AI
  > Amazon Web Services on Tuesday announced a new class of artificial intelligence systems called "frontier agents" that can work autonomously for hours or even days without human intervention, representing one of the most ambitious attempts yet to automate the full software development lifecycle.The announcement, made during AWS CEO Matt Garman's keynote address at the company's annual re:Invent conference, introduces three specialized AI agents designed to act as virtual team members: Kiro autonomous agent for software development, AWS Security Agent for application security, and AWS DevOps Agent for IT operations.The move signals Amazon's intent to leap ahead in the intensifying competition to build AI systems capable of performing complex, multi-step tasks that currently require teams of skilled engineers."We see frontier agents as a completely new class of agents," said Deepak Singh, vice president of developer agents and experiences at Amazon, in an interview ahead of the announcement. "They're fundamentally designed to work for hours and days. You're not giving them a problem that you want finished in the next five minutes. You're giving them complex challenges that they may have to think about, try different solutions, and get to the right conclusion — and they should do that without intervention."Why Amazon believes its new agents leave existing AI coding tools behindThe frontier agents differ from existing AI coding assistants like GitHub Copilot or Amazon's own CodeWhisperer in several fundamental ways.Current AI coding tools, while powerful, require engineers to drive every interaction. Developers must write prompts, provide context, and manually coordinate work across different code repositories. When switching between tasks, the AI loses context and must start fresh.The new frontier agents, by contrast, maintain persistent memory across sessions and continuously learn from an organization's codebase, documentation, and team communications. They can independently determine which code repositories require changes, work on multiple files simultaneously, and coordinate complex transformations spanning dozens of microservices."With a current agent, you would go microservice by microservice, making changes one at a time, and each change would be a different session with no shared context," Singh explained. "With a frontier agent, you say, 'I need to solve this broad problem.' You point it to the right application, and it decides which repos need changes."The agents exhibit three defining characteristics that AWS believes set them apart: autonomy in decision-making, the ability to scale by spawning multiple agents to work on different aspects of a problem simultaneously, and the capacity to operate independently for extended periods."A frontier agent can decide to spin up 10 versions of itself, all working on different parts of the problem at once," Singh said.How each of the three frontier agents tackles a different phase of developmentKiro autonomous agent serves as a virtual developer that maintains context across coding sessions and learns from an organization's pull requests, code reviews, and technical discussions. Teams can connect it to GitHub, Jira, Slack, and internal documentation systems. The agent then acts like a teammate, accepting task assignments and working independently until it either completes the work or requires human guidance.AWS Security Agent embeds security expertise throughout the development process, automatically reviewing design documents and scanning pull requests against organizational security requirements. Perhaps most significantly, it transforms penetration testing from a weeks-long manual process into an on-demand capability that completes in hours.SmugMug, a photo hosting platform, has already deployed the security agent. "AWS Security Agent helped catch a business logic bug that no existing tools would have caught, exposing information improperly," said Andres Ruiz, staff software engineer at the company. "To any other tool, this would have been invisible. But the ability for Security Agent to contextualize the information, parse the API response, and find the unexpected information there represents a leap forward in automated security testing."AWS DevOps Agent functions as an always-on operations team member, responding instantly to incidents and using its accumulated knowledge to identify root causes. It connects to observability tools including Amazon CloudWatch, Datadog, Dynatrace, New Relic, and Splunk, along with runbooks and deployment pipelines.Commonwealth Bank of Australia tested the DevOps agent by replicating a complex network and identity management issue that typically requires hours for experienced engineers to diagnose. The agent identified the root cause in under 15 minutes."AWS DevOps Agent thinks and acts like a seasoned DevOps engineer, helping our engineers build a banking infrastructure that's faster, more resilient, and designed to deliver better experiences for our customers," said Jason Sandry, head of cloud services at Commonwealth Bank.Amazon makes its case against Google and Microsoft in the AI coding warsThe announcement arrives amid a fierce battle among technology giants to dominate the emerging market for AI-powered development tools. Google has made significant noise in recent weeks with its own AI coding capabilities, while Microsoft continues to advance GitHub Copilot and its broader AI development toolkit.Singh argued that AWS holds distinct advantages rooted in the company's 20-year history operating cloud infrastructure and Amazon's own massive software engineering organization."AWS has been the cloud of choice for 20 years, so we have two decades of knowledge building and running it, and working with customers who've been building and running applications on it," Singh said. "The learnings from operating AWS, the knowledge our customers have, the experience we've built using these tools ourselves every day to build real-world applications—all of that is embodied in these frontier agents."He drew a distinction between tools suitable for prototypes versus production systems. "There's a lot of things out there that you can use to build your prototype or your toy application. But if you want to build production applications, there's a lot of knowledge that we bring in as AWS that apply here."The safeguards Amazon built to keep autonomous agents from going rogueThe prospect of AI systems operating autonomously for days raises immediate questions about what happens when they go off track. Singh described multiple safeguards built into the system.All learnings accumulated by the agents are logged and visible, allowing engineers to understand what knowledge influences the agent's decisions. Teams can even remove specific learnings if they discover the agent has absorbed incorrect information from team communications."You can go in and even redact that from its knowledge like, 'No, we don't want you to ever use this knowledge,'" Singh said. "You can look at the knowledge like it's almost—it's like looking at your neurons inside your brain. You can disconnect some."Engineers can also monitor agent activity in real-time and intervene when necessary, either redirecting the agent or taking over entirely. Most critically, the agents never commit code directly to production systems. That responsibility remains with human engineers."These agents are never going to check the code into production. That is still the human's responsibility," Singh emphasized. "You are still, as an engineer, responsible for the code you're checking in, whether it's generated by you or by an agent working autonomously."What frontier agents mean for the future of software engineering jobsThe announcement inevitably raises concerns about the impact on software engineering jobs. Singh pushed back against the notion that frontier agents will replace developers, framing them instead as tools that amplify human capabilities."Software engineering is craft. What's changing is not, 'Hey, agents are doing all the work.' The craft of software engineering is changing—how you use agents, how do you set up your code base, how do you set up your prompts, how do you set up your rules, how do you set up your knowledge bases so that agents can be effective," he said.Singh noted that senior engineers who had drifted away from hands-on coding are now writing more code than ever. "It's actually easier for them to become software engineers," he said.He pointed to an internal example where a team completed a project in 78 days that would have taken 18 months using traditional practices. "Because they were able to use AI. And the thing that made it work was not just the fact that they were using AI, but how they organized and set up their practices of how they built that software were maximized around that."How Amazon plans to make AI-generated code more trustworthy over timeSingh outlined several areas where frontier agents will evolve over the coming years. Multi-agent architectures, where systems of specialized agents coordinate to solve complex problems, represent a major frontier. So does the integration of formal verification techniques to increase confidence in AI-generated code.AWS recently introduced property-based testing in Kiro, which uses automated reasoning to extract testable properties from specifications and generate thousands of test scenarios automatically."If you have a shopping cart application, every way an order can be canceled, and how it might be canceled, and the way refunds are handled in Germany versus the US—if you're writing a unit test, maybe two, Germany and US, but now, because you have this property-based testing approach, your agent can create a scenario for every country you operate in and test all of them automatically for you," Singh explained.Building trust in autonomous systems remains the central challenge. "Right now you still require tons of human guardrails at every step to make sure that the right thing happens. And as we get better at these techniques, you will use less and less, and you'll be able to trust the agents a lot more," he said.Amazon's bigger bet on autonomous AI stretches far beyond writing codeThe frontier agents announcement arrived alongside a cascade of other news at re:Invent 2025. AWS kicked off the conference with major announcements on agentic AI capabilities, customer service innovations, and multicloud networking.Amazon expanded its Nova portfolio with four new models delivering industry-leading price-performance across reasoning, multimodal processing, conversational AI, code generation, and agentic tasks. Nova Forge pioneers "open training," giving organizations access to pre-trained model checkpoints and the ability to blend proprietary data with Amazon Nova-curated datasets.AWS also added 18 new open weight models to Amazon Bedrock, reinforcing its commitment to offering a broad selection of fully managed models from leading AI providers. The launch includes new models from Mistral AI, Google's Gemma 3, MiniMax's M2, NVIDIA's Nemotron, and OpenAI's GPT OSS Safeguard.On the infrastructure side, Amazon EC2 Trn3 UltraServers, powered by AWS's first 3nm AI chip, pack up to 144 Trainium3 chips into a single integrated system, delivering up to 4.4x more compute performance and 4x greater energy efficiency than the previous generation. AWS AI Factories provides enterprises and government organizations with dedicated AWS AI infrastructure deployed in their own data centers, combining NVIDIA GPUs, Trainium chips, AWS networking, and AI services like Amazon Bedrock and SageMaker AI.All three frontier agents launched in preview on Tuesday. Pricing will be announced when the services reach general availability.Singh made clear the company sees applications far beyond coding. "These are the first frontier agents we are releasing, and they're in the software development lifecycle," he said. "The problems and use cases for frontier agents—these agents that are long running, capable of autonomy, thinking, always learning and improving—can be applied to many, many domains."Amazon, after all, operates satellite networks, runs robotics warehouses, and manages one of the world's largest e-commerce platforms. If autonomous agents can learn to write code on their own, the company is betting they can eventually learn to do just about anything else.
- [New AWS AI Factories transform customers’ existing infrastructure into high-performance AI environments - About Amazon](https://news.google.com/rss/articles/CBMidEFVX3lxTE5PbXIwWnB4NnVqUnBicEhTcHRLSzRXY3V3cW5GaXpXN0FZRXM4U21ZeThNWDRGWVFXNUJPWk5VNWFuYWtCTjJOUHpodVlLQVdadlVDWVRTVjhSVzJZTzRFVTdNcHlUT05iczlSeE03N2FueHdM?oc=5) — 07:59 · Google News (AI)
  > New AWS AI Factories transform customers’ existing infrastructure into high-performance AI environments  About Amazon
- [Mistral launches Mistral 3, a family of open models designed to run on laptops, drones, and edge devices](https://venturebeat.com/ai/mistral-launches-mistral-3-a-family-of-open-models-designed-to-run-on) — 07:00 · VentureBeat AI
  > Mistral AI, Europe's most prominent artificial intelligence startup, is releasing its most ambitious product suite to date: a family of 10 open-source models designed to run everywhere from smartphones and autonomous drones to enterprise cloud systems, marking a major escalation in the company's challenge to both U.S. tech giants and surging Chinese competitors.The Mistral 3 family, launching today, includes a new flagship model called Mistral Large 3 and a suite of smaller "Ministral 3" models optimized for edge computing applications. All models will be released under the permissive Apache 2.0 license, allowing unrestricted commercial use — a sharp contrast to the closed systems offered by OpenAI, Google, and Anthropic.The release is a pointed bet by Mistral that the future of artificial intelligence lies not in building ever-larger proprietary systems, but in offering businesses maximum flexibility to customize and deploy AI tailored to their specific needs, often using smaller models that can run without cloud connectivity."The gap between closed and open source is getting smaller, because more and more people are contributing to open source, which is great," Guillaume Lample, Mistral's chief scientist and co-founder, said in an exclusive interview with VentureBeat. "We are catching up fast."Why Mistral is choosing flexibility over frontier performance in the AI raceThe strategic calculus behind Mistral 3 diverges sharply from recent model releases by industry leaders. While OpenAI, Google, and Anthropic have focused recent launches on increasingly capable "agentic" systems — AI that can autonomously execute complex multi-step tasks — Mistral is prioritizing breadth, efficiency, and what Lample calls "distributed intelligence."Mistral Large 3, the flagship model, employs a Mixture of Experts architecture with 41 billion active parameters drawn from a total pool of 675 billion parameters. The model can process both text and images, handles context windows up to 256,000 tokens, and was trained with particular emphasis on non-English languages — a rarity among frontier AI systems."Most AI labs focus on their native language, but Mistral Large 3 was trained on a wide variety of languages, making advanced AI useful for billions who speak different native languages," the company said in a statement reviewed ahead of the announcement.But the more significant departure lies in the Ministral 3 lineup: nine compact models across three sizes (14 billion, 8 billion, and 3 billion parameters) and three variants tailored for different use cases. Each variant serves a distinct purpose: base models for extensive customization, instruction-tuned models for general chat and task completion, and reasoning-optimized models for complex logic requiring step-by-step deliberation.The smallest Ministral 3 models can run on devices with as little as 4 gigabytes of video memory using 4-bit quantization — making frontier AI capabilities accessible on standard laptops, smartphones, and embedded systems without requiring expensive cloud infrastructure or even internet connectivity. This approach reflects Mistral's belief that AI's next evolution will be defined not by sheer scale, but by ubiquity: models small enough to run on drones, in vehicles, in robots, and on consumer devices.How fine-tuned small models beat expensive large models for enterprise customersLample's comments reveal a business model fundamentally different from that of closed-source competitors. Rather than competing primarily on benchmark performance, Mistral is targeting enterprise customers frustrated by the cost and inflexibility of proprietary systems."Sometimes customers say, 'Is there a use case where the best closed-source model isn't working?' If that's the case, then they're essentially stuck," Lample explained. "There's nothing they can do. It's the best model available, and it's not working out of the box."This is where Mistral's approach diverges. When a generic model fails, the company deploys engineering teams to work directly with customers, analyzing specific problems, creating synthetic training data, and fine-tuning smaller models to outperform larger general-purpose systems on narrow tasks."In more than 90% of cases, a small model can do the job, especially if it's fine-tuned. It doesn't have to be a model with hundreds of billions of parameters, just a 14-billion or 24-billion parameter model," Lample said. "So it's not only much cheaper, but also faster, plus you have all the benefits: you don't need to worry about privacy, latency, reliability, and so on."The economic argument is compelling. Multiple enterprise customers have approached Mistral after building prototypes with expensive closed-source models, only to find deployment costs prohibitive at scale, according to Lample."They come back to us a couple of months later because they realize, 'We built this prototype, but it's way too slow and way too expensive,'" he said.Where Mistral 3 fits in the increasingly crowded open-source AI marketMistral's release comes amid fierce competition on multiple fronts. OpenAI recently released GPT-5.1 with enhanced agentic capabilities. Google launched Gemini 3 with improved multimodal understanding. Anthropic released Opus 4.5 on the same day as this interview, with similar agent-focused features.But Lample argues those comparisons miss the point. "It's a little bit behind. But I think what matters is that we are catching up fast," he acknowledged regarding performance against closed models. "I think we are maybe playing a strategic long game."That long game involves a different competitive set: primarily open-source models from Chinese companies like DeepSeek and Alibaba's Qwen series, which have made remarkable strides in recent months.Mistral differentiates itself through multilingual capabilities that extend far beyond English or Chinese, multimodal integration handling both text and images in a unified model, and what the company characterizes as superior customization through easier fine-tuning."One key difference with the models themselves is that we focused much more on multilinguality," Lample said. "If you look at all the top models from [Chinese competitors], they're all text-only. They have visual models as well, but as separate systems. We wanted to integrate everything into a single model."The multilingual emphasis aligns with Mistral's broader positioning as a European AI champion focused on digital sovereignty — the principle that organizations and nations should maintain control over their AI infrastructure and data.Building beyond models: Mistral's full-stack enterprise AI platform strategyMistral 3's release builds on an increasingly comprehensive enterprise AI platform that extends well beyond model development. The company has assembled a full-stack offering that differentiates it from pure model providers.Recent product launches include Mistral Agents API, which combines language models with built-in connectors for code execution, web search, image generation, and persistent memory across conversations; Magistral, the company's reasoning model designed for domain-specific, transparent, and multilingual reasoning; and Mistral Code, an AI-powered coding assistant bundling models, an in-IDE assistant, and local deployment options with enterprise tooling.The consumer-facing Le Chat assistant has been enhanced with Deep Research mode for structured research reports, voice capabilities, and Projects for organizing conversations into context-rich folders. More recently, Le Chat gained a connector directory with 20+ enterprise integrations powered by the Model Context Protocol (MCP), spanning tools like Databricks, Snowflake, GitHub, Atlassian, Asana, and Stripe.In October, Mistral unveiled AI Studio, a production AI platform providing observability, agent runtime, and AI registry capabilities to help enterprises track output changes, monitor usage, run evaluations, and fine-tune models using proprietary data.Mistral now positions itself as a full-stack, global enterprise AI company, offering not just models but an application-building layer through AI Studio, compute infrastructure, and forward-deployed engineers to help businesses realize return on investment.Why open source AI matters for customization, transparency and sovereigntyMistral's commitment to open-source development under permissive licenses is both an ideological stance and a competitive strategy in an AI landscape increasingly dominated by closed systems.Lample elaborated on the practical benefits: "I think something that people don't realize — but our customers know this very well — is how much better any model can actually improve if you fine tune it on the task of interest. There's a huge gap between a base model and one that's fine-tuned for a specific task, and in many cases, it outperforms the closed-source model."The approach enables capabilities impossible with closed systems: organizations can fine-tune models on proprietary data that never leaves their infrastructure, customize architectures for specific workflows, and maintain complete transparency into how AI systems make decisions — critical for regulated industries like finance, healthcare, and defense.This positioning has attracted government and public sector partnerships. The company launched "AI for Citizens" in July 2025, an initiative to "help States and public institutions strategically harness AI for their people by transforming public services" and has secured strategic partnerships with France's army and job agency, Luxembourg's government, and various European public sector organizations.Mistral's transatlantic AI collaboration goes beyond European bordersWhile Mistral is frequently characterized as Europe's answer to OpenAI, the company views itself as a transatlantic collaboration rather than a purely European venture. The company has teams across both continents, with co-founders spending significant time with customers and partners in the United States, and these models are being trained in partnerships with U.S.-based teams and infrastructure providers.This transatlantic positioning may prove strategically important as geopolitical tensions around AI development intensify. The recent ASML investment, a €1.7 billion ($1.5 billion) funding round led by the Dutch semiconductor equipment manufacturer, signals deepening collaboration across the Western semiconductor and AI value chain at a moment when both Europe and the United States are seeking to reduce dependence on Chinese technology.Mistral's investor base reflects this dynamic: the Series C round included participation from U.S. firms Andreessen Horowitz, General Catalyst, Lightspeed, and Index Ventures alongside European investors like France's state-backed Bpifrance and global players like DST Global and Nvidia.Founded in May 2023 by former Google DeepMind and Meta researchers, Mistral has raised roughly $1.05 billion (€1 billion) in funding. The company was valued at $6 billion in a June 2024 Series B, then more than doubled its valuation in a September Series C.Can customization and efficiency beat raw performance in enterprise AI?The Mistral 3 release crystallizes a fundamental question facing the AI industry: Will enterprises ultimately prioritize the absolute cutting-edge capabilities of proprietary systems, or will they choose open, customizable alternatives that offer greater control, lower costs, and independence from big tech platforms?Mistral's answer is unambiguous. The company is betting that as AI moves from prototype to production, the factors that matter most shift dramatically. Raw benchmark scores matter less than total cost of ownership. Slight performance edges matter less than the ability to fine-tune for specific workflows. Cloud-based convenience matters less than data sovereignty and edge deployment.It's a wager with significant risks. Despite Lample's optimism about closing the performance gap, Mistral's models still trail the absolute frontier. The company's revenue, while growing, reportedly remains modest relative to its nearly $14 billion valuation. And competition intensifies from both well-funded Chinese rivals making remarkable open-source progress and U.S. tech giants increasingly offering their own smaller, more efficient models.But if Mistral is right — if the future of AI looks less like a handful of cloud-based oracles and more like millions of specialized systems running everywhere from factory floors to smartphones — then the company has positioned itself at the center of that transformation.The release of Mistral 3 is the most comprehensive expression yet of that vision: 10 models, spanning every size category, optimized for every deployment scenario, available to anyone who wants to build with them.Whether "distributed intelligence" becomes the industry's dominant paradigm or remains a compelling alternative serving a narrower market will determine not just Mistral's fate, but the broader question of who controls the AI future — and whether that future will be open.For now, the race is on. And Mistral is betting it can win not by building the biggest model, but by building everywhere else.
- [Ascentra Labs raises $2 million to help consultants use AI instead of all-night Excel marathons](https://venturebeat.com/ai/ascentra-labs-raises-usd2-million-to-help-consultants-use-ai-instead-of-all) — 06:00 · VentureBeat AI
  > While artificial intelligence has stormed into law firms and accounting practices with billion-dollar startups like Harvey leading the charge, the global consulting industry—a $250 billion behemoth—has remained stubbornly analog. A London-based startup founded by former McKinsey consultants is betting $2 million that it can crack open this resistant market, one Excel spreadsheet at a time.Ascentra Labs announced Tuesday that it has closed a $2 million seed round led by NAP, a Berlin-based venture capital firm formerly known as Cavalry Ventures. The funding comes with participation from notable founder-angels including Alan Chang, chief executive of Fuse and former chief revenue officer at Revolut, and Fredrik Hjelm, chief executive of European e-scooter company Voi.The investment is modest by the standards of enterprise AI — a sector that has seen funding rounds routinely reach into the hundreds of millions. But Ascentra's founders argue that their focused approach to a narrow but painful problem could give them an edge in a market where broad AI solutions have repeatedly failed to gain traction.Consultants spend countless hours on Excel survey analysis that even top firms haven't automatedParitosh Devbhandari, Ascentra's co-founder and chief executive, spent years at McKinsey & Company, including a stint at QuantumBlack, the firm's AI and advanced analytics division. He knows intimately the late nights consultants spend wrestling with survey data—the kind of quantitative research that forms the backbone of private equity due diligence."Before starting the company, I was working at McKinsey, specifically on the private equity team," Devbhandari explained in an exclusive interview with VentureBeat. The work, he said, involves analyzing encoded survey responses from customers, suppliers, and market participants during potential acquisitions."Consultants typically spend a lot of time doing this in Excel," he said. "One of the things that surprised me, having worked at a couple of different places, is that the workflow — even at the best firms — really isn't that different from some of the boutiques. I always expected there would be some smarter way of doing things, and often there just isn't."That gap between expectation and reality became the foundation for Ascentra. The company's platform ingests raw survey data files and outputs formatted Excel workbooks complete with traceable formulas — the kind of deliverable a junior associate would spend hours constructing manually.AI has transformed legal work but consulting presents unique technical challenges that have blocked adoptionThe disparity between AI adoption in law versus consulting raises an obvious question: if the consulting market is so large and the workflows so manual, why hasn't venture capital flooded the space the way it has legal tech?Devbhandari offered a frank assessment. "It's not like people haven't tried," he said. "The top of the funnel in our space is crowded. When we speak to our consulting clients, the partners say they get another pitch deck in their LinkedIn inbox or email every week—sometimes several. There are plenty of people trying."The barriers, he argued, are structural. Professional services firms move slowly on technology adoption, demanding extensive security credentials and customer references before granting even a pilot opportunity. "I think that's where 90% of startups in professional services, writ large, fall down," he said.But consulting presents unique technical challenges beyond the sales cycle. Unlike legal work, which largely involves text documents that modern large language models handle well, consulting spans multiple data modalities — PowerPoint presentations, Excel spreadsheets, Word documents — with information that can be tabular, graphical, or textual."You can have multiple formats of Excel in itself," Devbhandari noted. "And that's a big contrast to the legal space, where you could have a multi-purpose AI agent, or collection of agents, which can actually do a lot of the tasks that lawyers do day to day. Consulting is the opposite of that."Ascentra's private equity focus reflects a calculated bet on repeatable workflowsAscentra's strategy hinges on extreme specificity. Rather than attempting to automate the full spectrum of consulting work, the company focuses exclusively on survey analysis within private equity due diligence — a niche within a niche.The logic is both technical and commercial. Private equity work tends to be more standardized than other consulting engagements, with similar analyses recurring across deals. That repeatability makes automation feasible. It also positions Ascentra against a less formidable competitive set: even the largest consulting firms, Devbhandari claimed, lack dedicated internal tools for this particular workflow."Survey analysis automation is so specific that even the biggest and best firms haven't developed anything in-house for it," he said.The company claims that three of the world's top five consulting firms now use its platform, with early adopters reporting time savings of 60 to 80 percent on active due diligence projects. But there's a notable caveat: Ascentra cannot publicly name any of these clients."It's a very private industry, so at the moment, we can't announce any clients publicly," Devbhandari acknowledged. "What I can say is that we're working with three of the top five consulting firms. We've passed pilots at multiple organizations and have submitted business cases for enterprise rollouts."Eliminating AI hallucinations becomes critical when billion-dollar deals hang in the balanceFor an AI company selling into quantitative workflows, accuracy is existential. Consultants delivering analysis to private equity clients face enormous pressure to be precise—a single error in a financial model can undermine credibility and, potentially, billion-dollar investment decisions.Devbhandari described this as Ascentra's central design challenge. "Consultants require a very, very high degree of fidelity when they're doing their analysis," he said. "So with quantitative data, even if it's 95% accurate, they will revert to Excel because they know it, they trust it, and they don't want there to be any margin for error."Ascentra's technical approach attempts to address this by limiting where AI models operate within the workflow. The company uses GPT-based models from OpenAI to interpret and ingest incoming data, but the actual analysis relies on deterministic Python scripts that produce consistent, verifiable outputs."What's different is the steps that follow are deterministic," Devbhandari explained. "There's no room for error. There's no hallucinations, and the Excel writer that we've connected to the product on the back end converts this analysis into Excel formula, which are live and traceable, so consultants can get that assurance that they can follow along with the maths."Whether this hybrid approach delivers on its promise of eliminating hallucinations while maintaining useful AI capabilities will be tested as the platform scales across more complex use cases and client environments.Enterprise security certifications give Ascentra an edge over less prepared competitorsSelling software to major consulting firms requires clearing an unusually high security bar. These organizations handle sensitive client data across industries, and their vendor security assessments can take months to complete.Ascentra invested early in obtaining enterprise-grade certifications, a strategic choice that Devbhandari framed as essential table stakes. The company has achieved SOC 2 Type II and ISO 27001 certifications and claims to be under audit for ISO 42001, an emerging standard for AI management systems.Data handling policies also reflect the sensitivity of the target market. Client data is deleted within 30 to 45 days, depending on contractual terms, and Ascentra does not use customer data to train its models.There's also an argument that survey data carries somewhat lower sensitivity than other consulting materials. "Survey data is unique in consulting data because it's collected during the course of a project, and it is market data," Devbhandari noted. "You interview people in the market, and you collect a bunch of data in an Excel, as opposed to—you look at Rogo or some of the other finance AI startups—they use client data, so financials, which is confidential and strictly non-public."Per-project pricing aligns with how consulting firms actually spend moneyAscentra's pricing model departs from the subscription-based approach that dominates enterprise software. The company charges on a per-project basis, a structure Devbhandari said aligns with how consulting firms allocate budgets."Project budgets are in consulting set on a per project basis," he explained. "You'll have central budgets which are for things like Microsoft, right, very central things that every team will use all of the time. And then you have project budgets which are for the teams that are using specific resources, teams or products nowadays."This approach may ease initial adoption by avoiding the need for central IT procurement approval, but it also introduces revenue unpredictability. The company's success will depend on converting project-level usage into broader enterprise relationships—a path Devbhandari suggested is already underway through submitted business cases for enterprise rollouts.AI may not eliminate consulting jobs, but it will fundamentally transform what consultants doPerhaps the most interesting tension in Devbhandari's vision concerns what AI ultimately means for consulting employment. He pushed back on predictions that AI will eliminate consulting jobs while simultaneously describing an industry on the cusp of fundamental transformation."People love to talk about how AI is going to remove the need for consultants, and I disagree," he said. "Yes, the role will change, but I don't think the industry goes away. I think the best solutions will come from people within the industry building products around the work they know."Yet he also painted a picture of dramatic change. "At the moment, you have a big intake of graduates who just do—for the most part, you know, they have the strategic work as part of what they do, but they also have a lot of work in Excel and PowerPoint. I think in a few years' time, we'll look back at these times and think, you know, very, very different."The honest answer, he acknowledged, is that no one truly knows how this plays out. "I don't think even AI leaders truly know what that looks like yet," he said of whether productivity gains will translate to more work or fewer workers.Ascentra plans to use seed funding to expand its U.S. presence and go-to-market teamThe $2 million will primarily fund Ascentra's expansion into the United States, where more than 80 percent of its customers are already based. Devbhandari plans to relocate there personally as the company builds out go-to-market capabilities."One of the things that we've really noticed is that with consulting being an American industry, and I think America being a great place for innovation and trying new things, we've definitely drawn ourselves to the U.S.," he said. "American hires are very expensive, and I'm sure that a lot of the raise will go towards that."The seed round represents a bet by NAP on what its co-founder Stefan Walter called an overdue disruption. "While most knowledge work has been reshaped by new technology, consulting has remained stubbornly manual," Walter said. "AI won't replace consultants, but consultants using Ascentra might."The startup now faces the hard work of converting pilot wins into lasting enterprise contractsAscentra enters 2026 with momentum but no guarantee of success. The company must transform pilot programs at elite firms into sticky enterprise contracts — all while fending off the inevitable well-funded competitors who will flood into the space once the opportunity becomes undeniable. Its deliberately narrow focus on survey analysis provides a defensible beachhead, but expanding into adjacent workflows will require building entirely new products without sacrificing the domain expertise that Devbhandari argues is the company's core advantage.Oliver Thurston, Ascentra's co-founder and chief technology officer, who previously led machine learning at Mathison AI, offered a clear-eyed assessment of the challenge. "Consulting workflows are uniquely complex and difficult to build products around," he said in a statement. "It's not surprising the space hasn't changed yet. This will change though, and there's no doubt that the industry is going to look completely different in five years' time."For now, Ascentra is placing a focused wager: that the consultants who once spent their nights formatting spreadsheets will be the ones who finally bring AI into an industry that has long resisted it. The irony is hard to miss. After years of advising Fortune 500 companies on digital transformation, consulting may finally have to take its own medicine.
- [The Download: AI’s impact on the economy, and DeepSeek strikes again](https://www.technologyreview.com/2025/12/02/1128647/the-download-ais-impact-on-the-economy-and-deepseek-strikes-again/) — 05:10 · MIT Technology Review (AI)
  > This is today’s edition of The Download, our weekday newsletter that provides a daily dose of what’s going on in the world of technology. The State of AI: Welcome to the economic singularity —David Rotman and Richard Waters Any far-reaching new technology is always uneven in its adoption, but few have been more uneven than generative AI.…
- [New training method boosts AI multimodal reasoning with smaller, smarter datasets](https://venturebeat.com/ai/new-training-method-boosts-ai-multimodal-reasoning-with-smaller-smarter) — 04:30 · VentureBeat AI
  > Researchers at MiroMind AI and several Chinese universities have released OpenMMReasoner, a new training framework that improves the capabilities of language models in multimodal reasoning.The framework uses a two-stage process. It first refines a base model with a curated dataset in a supervised fine-tuning (SFT) stage. Then, a reinforcement learning (RL) stage guides the model to reason more effectively in tasks that involve both text and visual data. Experiments show that models trained with OpenMMReasoner outperform other leading visual reasoning models, often while being trained on a smaller, higher-quality dataset. The framework and all its assets, including a trained 7B model, are fully open source, providing a reliable foundation for building applications that require traceability and robustness.According to Kaichen Zhang, co-author of a research paper that outlines the new method, OpenMMReasoner offers significant benefits for businesses looking beyond large, closed systems. "A smaller open-source reasoning model has practical advantages: Enterprises can deploy it locally, reduce latency, lower token costs associated with long chains of thought, maintain full control over their data and [it is] fine-tunable to adapt to their specific downstream task," he told VentureBeat.The challenge of transparent multimodal reasoningRecent advances in reinforcement learning with verifiable rewards (RLVR) have significantly improved the reasoning abilities of large language models (LLMs). RLVR trains LLMs to generate chain-of-thought (CoT) tokens (which mimic the reasoning processes humans use) before generating the final answer. This improves the model’s capability to solve complex reasoning tasks such as math and coding. Motivated by this success, researchers have applied similar RL-based methods to large multimodal models (LMMs), showing that the benefits can extend beyond text to improve visual understanding and problem-solving across different modalities.However, a lack of transparency in the training pipeline has been a major barrier. Many studies on multimodal reasoning do not provide detailed information about their data curation and training processes, making it difficult to reproduce their results or understand what makes these models work.“This lack of openness restricts reproducibility and obscures a deeper understanding of how reasoning-capable LMMs are actually built and how their training dynamics evolve,” the researchers note.The OpenMMReasoner recipeOpenMMReasoner addresses this gap with a fully transparent and scalable training recipe built on open-source LMMs. The researchers found it was critical to curate high-quality datasets by scaling data diversity. Although using diverse data sources is important, increasing the diversity of correct answers for the same question was an essential axis for improvement.The first stage of the recipe is a three-step supervised fine-tuning (SFT) pipeline. It begins with data sourcing, where the team collected approximately 103,000 raw question-answer pairs from public datasets covering general visual Q&A and reasoning tasks. Next, they added a data distillation step, using a powerful model (Qwen3-VL-235B-Instruct) to generate new, high-quality reasoning traces for selected questions. (The data will then be used to train a smaller model.)To increase answer diversity, the team generated multiple verified reasoning traces for each question. This expanded the dataset to 583,000 samples. Finally, they implemented a “domain mixing” phase, adding data from mathematical reasoning domains to further generalize the model's capabilities, resulting in a final SFT dataset of 874,000 examples.The second stage is an RL recipe that uses a smaller, 74,000-sample dataset curated from domains like science, math and puzzles. The model is trained with a composite reward function that considers both the correctness of the final answer and the consistency of the output format. To improve efficiency, the process includes a penalty for "overthinking," discouraging the model from generating excessively long answers (a problem with many reasoning models trained through RL, which mistakenly learn to generate overly long reasoning sequences, resulting in excess cost and slower answers).This recipe can provide a blueprint for enterprises training their own models. "For companies with limited domain-specific data, a feasible strategy is to first increase answer diversity for their existing dataset, then use domain mixing to integrate this domain data into a general reasoning recipe like ours," Zhang explained. "This allows the model to acquire strong general-purpose reasoning skills while also adapting to industry-specific tasks, without needing millions of samples."A more efficient and capable reasoning modelAccording to Zhang, the step-by-step process fundamentally changes the reliability of the model's outputs. "Traditional models often 'jump' directly to an answer, which means they explore only a narrow portion of the reasoning space," he said. "In contrast, a reasoning-first approach forces the model to explicitly examine multiple intermediate steps... [allowing it] to traverse much deeper paths and arrive at answers with far more internal consistency."The researchers used the OpenMMReasoner recipe to generate data to fine-tune the Qwen2.5-VL-7B-Instruct open-source vision-language model. The result is a highly capable LMM that consistently outperforms state-of-the-art methods, such as Open Vision Reasoner (OVR), across a wide range of multimodal reasoning benchmarks. The SFT stage alone creates a strong baseline model that achieves superior performance and data efficiency compared to other SFT approaches, despite using a significantly smaller training dataset.The subsequent RL phase further sharpens and stabilizes these abilities, leading to more consistent and improved performance. After RL, the final model achieves state-of-the-art results on several benchmarks, including WeMath, MathVerse and MathVista.One of the key findings was that, as the model improved at multimodal reasoning, it also showed a "gradual emergence of textual reasoning behaviors, suggesting a transfer of reasoning competence from multimodal to purely linguistic domains," the researchers note. This indicates that skills learned in one modality can strengthen performance in another. "Our results show that strengthening multimodal reasoning can even improve text-only mathematical skills—evidence that core logical abilities can transfer across modalities," Zhang said. "Looking ahead, we do expect these methods to extend to video and audio."The researchers also found that token efficiency is crucial. While allowing a model to generate longer reasoning steps can improve performance, excessive tokens reduce efficiency. Their results show that setting a smaller "reasoning budget" can achieve comparable or even better accuracy, an important consideration for deploying cost-effective enterprise applications.By open-sourcing all components of their workflow, the researchers provide a reproducible view of the entire process. For enterprise teams, this transparency is invaluable. "For business leaders concerned about vendor lock-in, hidden biases or opaque data sources, this level of transparency is essential," Zhang stated. "It empowers teams to validate the data, customize the pipeline for new domains and maintain long-term independence from any single provider."
