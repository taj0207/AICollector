# AI News for 2025-12-14 (America/Los_Angeles)

Collected 4 article(s).

- [AI Use at Work Rises - Gallup.com](https://news.google.com/rss/articles/CBMic0FVX3lxTE10dVlQT2hwUldUMTFTVHZjeVU1dU5TemZUY0t2SzRlN3pyZzJqX1ZmWFp2cDRvTUhDd2xtdENUam9iVmw0YXpiSnYxT1JuWnAzVVJ6cGctc2ptSlZ1NHBsdnh0MkRMQjRmSktoZHY1OWNhME0?oc=5) — 21:03 · Google News (AI)
  > AI Use at Work Rises  Gallup.com
- [Why agentic AI needs a new category of customer data](https://venturebeat.com/ai/why-agentic-ai-needs-a-new-category-of-customer-data) — 21:00 · VentureBeat AI
  > Presented by TwilioThe customer data infrastructure powering most enterprises was architected for a world that no longer exists: one where marketing interactions could be captured and processed in batches, where campaign timing was measured in days (not milliseconds), and where "personalization" meant inserting a first name into an email template.Conversational AI has shattered those assumptions.AI agents need to know what a customer just said, the tone they used, their emotional state, and their complete history with a brand instantly to provide relevant guidance and effective resolution. This fast-moving stream of conversational signals (tone, urgency, intent, sentiment) represents a fundamentally different category of customer data. Yet the systems most enterprises rely on today were never designed to capture or deliver it at the speed modern customer experiences demand.The conversational AI context gapThe consequences of this architectural mismatch are already visible in customer satisfaction data. Twilio’s Inside the Conversational AI Revolution report reveals that more than half (54%) of consumers report AI rarely has context from their past interactions, and only 15% feel that human agents receive the full story after an AI handoff. The result: customer experiences defined by repetition, friction, and disjointed handoffs.The problem isn't a lack of customer data. Enterprises are drowning in it. The problem is that conversational AI requires real-time, portable memory of customer interactions, and few organizations have infrastructure capable of delivering it. Traditional CRMs and CDPs excel at capturing static attributes but weren't architected to handle the dynamic exchange of a conversation unfolding second by second.Solving this requires building conversational memory inside communications infrastructure itself, rather than attempting to bolt it onto legacy data systems through integrations.The agentic AI adoption wave and its limitsThis infrastructure gap is becoming critical as agentic AI moves from pilot to production. Nearly two-thirds of companies (63%) are already in late-stage development or fully deployed with conversational AI across sales and support functions.The reality check: While 90% of organizations believe customers are satisfied with their AI experiences, only 59% of consumers agree. The disconnect isn't about conversational fluency or response speed. It's about whether AI can demonstrate true understanding, respond with appropriate context, and actually solve problems rather than forcing escalation to human agents.Consider the gap: A customer calls about a delayed order. With proper conversational memory infrastructure, an AI agent could instantly recognize the customer, reference their previous order, details about a delay, proactively suggest solutions, and offer appropriate compensation, all without asking them to repeat information. Most enterprises can't deliver this because the required data lives in separate systems that can't be accessed quickly enough.Where enterprise data architecture breaks downEnterprise data systems built for marketing and support were optimized for structured data and batch processing, not the dynamic memory required for natural conversation. Three fundamental limitations prevent these systems from supporting conversational AI:Latency breaks the conversational contract. When customer data lives in one system and conversations happen in another, every interaction requires API calls that introduce 200-500 millisecond delays, transforming natural dialogue into robotic exchanges.Conversational nuance gets lost. The signals that make conversations meaningful (tone, urgency, emotional state, commitments made mid-conversation) rarely make it into traditional CRMs, which were designed to capture structured data, not the unstructured richness AI needs.Data fragmentation creates experience fragmentation. AI agents operate in one system, human agents in another, marketing automation in a third, and customer data in a fourth, creating fractured experiences where context evaporates at every handoff.Conversational memory requires infrastructure where conversations and customer data are unified by design.What unified conversational memory enablesOrganizations treating conversational memory as core infrastructure are seeing clear competitive advantages:Seamless handoffs: When conversational memory is unified, human agents inherit complete context instantly, eliminating the "let me pull up your account" dead time that signals wasted interactions.Personalization at scale: While 88% of consumers expect personalized experiences, over half of businesses cite this as a top challenge. When conversational memory is native to communications infrastructure, agents can personalize based on what customers are trying to accomplish right now.Operational intelligence: Unified conversational memory provides real-time visibility into conversation quality and key performance indicators, with insights feeding back into AI models to improve quality continuously.Agentic automation: Perhaps most significantly, conversational memory transforms AI from a transactional tool to a genuinely agentic system capable of nuanced decisions, like rebooking a frustrated customer's flight while offering compensation calibrated to their loyalty tier.The infrastructure imperativeThe agentic AI wave is forcing a fundamental re-architecture of how enterprises think about customer data.The solution isn't iterating on existing CDP or CRM architecture. It's recognizing that conversational memory represents a distinct category requiring real-time capture, millisecond-level access, and preservation of conversational nuance that can only be met when data capabilities are embedded directly into communications infrastructure.Organizations approaching this as a systems integration challenge will find themselves at a disadvantage against competitors who treat conversational memory as foundational infrastructure. When memory is native to the platform powering every customer touchpoint, context travels with customers across channels, latency disappears, and continuous journeys become operationally feasible.The enterprises setting the pace aren't those with the most sophisticated AI models. They're the ones that solved the infrastructure problem first, recognizing that agentic AI can't deliver on its promise without a new category of customer data purpose-built for the speed, nuance, and continuity that conversational experiences demand. Robin Grochol is SVP of Product, Data, Identity & Security at Twilio.Sponsored articles are content produced by a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact sales@venturebeat.com.
- [Grok is spreading misinformation about the Bondi Beach shooting](https://www.theverge.com/news/844443/grok-misinformation-bondi-beach-shooting) — 13:24 · The Verge (AI)
  > Grok's track record is spotty at best. But even by the very low standards of xAI, its failure in the aftermath of the tragic mass shooting at Bondi Beach in Australia is shocking. The AI chatbot has repeatedly misidentified 43-year-old Ahmed al Ahmed, the man who heroically disarmed one of the shooters and claimed the […]
- [Build vs buy is dead — AI just killed it](https://venturebeat.com/ai/build-vs-buy-is-dead-ai-just-killed-it) — 11:00 · VentureBeat AI
  > Picture this: You're sitting in a conference room, halfway through a vendor pitch. The demo looks solid, and pricing fits nicely under budget. The timeline seems reasonable too. Everyone’s nodding along.You’re literally minutes away from saying yes.Then someone from your finance team walks in. They see the deck and frown. A few minutes later, they shoot you a message on Slack: “Actually, I threw together a version of this last week. Took me 2 hours in Cursor. Wanna take a look?”Wait… what?This person doesn't code. You know for a fact they've never written a line of JavaScript in their entire life. But here they are, showing you a working prototype on their laptop that does... pretty much exactly what the vendor pitched. Sure, it's got some rough edges, but it works. And it didn’t cost six figures. Just two hours of their time.Suddenly, the assumptions you walked in with — about how software is developed, who makes it and how decisions are made around it — all start coming apart at the seams.The old frameworkFor decades, every growing company asked the same question: Should we build this ourselves, or should we buy it?And, for decades, the answer was pretty straightforward: Build if it's core to your business; buy if it isn’t.The logic made sense, because building was expensive and meant borrowing time from overworked engineers, writing specs, planning sprints, managing infrastructure and bracing yourself for a long tail of maintenance. Buying was faster. Safer. You paid for the support and the peace of mind.But something fundamental has changed: AI has made building accessible to everyone. What used to take weeks now takes hours, and what used to require fluency in a programming language now requires fluency in plain English.When the cost and complexity of building collapse this dramatically, the old framework goes down with them. It’s not build versus buy anymore. It’s something stranger that we haven't quite found the right words for.When the market doesn’t know what you need (yet)My company never planned to build so many of the tools we use. We just had to build because the things we needed didn’t exist. And, through that process, we developed this visceral understanding of what we actually wanted, what was useful and what it could or couldn't do. Not what vendor decks told us we needed or what analyst reports said we should want, but what actually moved the needle in our business.We figured out which problems were worth solving, which ones weren’t, where AI created real leverage and where it was just noise. And only then, once we had that hard-earned clarity, did we start buying.By that point, we knew exactly what we were looking for and could tell the difference between substance and marketing in about five minutes. We asked questions that made vendors nervous because we'd already built some rudimentary version of what they were selling.When anyone can build in minutesLast week, someone on our CX team noticed some customer feedback about a bug in Slack. Just a minor customer complaint, nothing major. In another company, this would’ve kicked off a support ticket and they’d have waited for someone else to handle it, but that’s not what happened here. They opened Cursor, described the change and let AI write the fix. Then they submitted a pull request that engineering reviewed and merged.Just 15 minutes after that complaint popped up in Slack, the fix was live in production.The person who did this isn’t technical in the slightest. I doubt they could tell you the difference between Python and JavaScript, but they solved the problem anyway. And that’s the point.AI has gotten so good at cranking out relatively simple code that it handles 80% of the problems that used to require a sprint planning meeting and two weeks of engineering time. It’s erasing the boundary between technical and non-technical. Work that used to be bottlenecked by engineering is now being done by the people closest to the problem.This is happening right now in companies that are actually paying attention.The inversion that’s happeningHere's where it gets fascinating for finance leaders, because AI has actually flipped the entire strategic logic of the build versus buy decision on its head.The old model went something like:Define the need.Decide whether to build or buy.But defining the need took forever and required deep technical expertise, or you'd burn through money through trial-and-error vendor implementations. You'd sit through countless demos, trying to picture whether this actually solved your problem. Then you’d negotiate, implement, move all your data and workflows to the new tool and six months and six figures later discover whether (or not) you were actually right.Now, the whole sequence gets turned around:Build something lightweight with AI.Use it to understand what you actually need.Then decide whether to buy (and you'll know exactly why).This approach lets you run controlled experiments. You figure out whether the problem even matters. You discover which features deliver value and which just look good in demos. Then you go shopping. Instead of letting some external vendor sell you on what the need is, you get to figure out whether you even have that need in the first place.Think about how many software purchases you've made that, in hindsight, solved problems you didn't actually have. How many times have you been three months into an implementation and thought, “Hang on, is this actually helping us, or are we just trying to justify what we spent?”Now, when you do buy, the question becomes “Does this solve the problem better than what we already proved we can build?”That one reframe changes the entire conversation. Now you show up to vendor calls informed. You ask sharper questions, and negotiate from a place of strength. Most importantly, you avoid the most expensive mistake in enterprise software, which is solving a problem you never really had.The trap you need to avoidAs this new capability emerges, I’m watching companies sprint in the wrong direction. They know they need to be AI native, so they go on a shopping spree. They look for AI-powered tools, filling their stack with products that have GPT integrations, chatbot UIs or “AI” slapped onto the marketing site. They think they’re transforming, but they’re not.Remember what physicist Richard Feynman called cargo cult science? After World War II, islanders in the South Pacific built fake airstrips and control towers, mimicking what they'd seen during the war, hoping planes full of cargo would return. They had all the outward forms of an airport: Towers, headsets, even people miming flight controllers. But no planes landed, because the form wasn’t the function.That’s exactly what’s happening with AI transformation in boardrooms everywhere. Leaders are buying AI tools without asking if they meaningfully change how work gets done, who they empower or what processes they unlock.They’ve built the airstrip, but the planes aren’t showing up.And the whole market's basically set up to make you fall into this trap. Everything gets branded as AI now, but nobody seems to care what these products actually do. Every SaaS product has bolted on a chatbot or an auto-complete feature and slapped an AI label on it, and the label has lost all meaning. It’s just a checkbox vendors figure they need to tick, regardless of whether it creates actual value for customers.The finance team’s new superpowerThis is the part that gets me excited about what finance teams can do now. You don’t have to guess anymore. You don’t have to bet six figures on a sales deck. You can test things, and you can actually learn something before you spend.Here's what I mean: If you’re evaluating vendor management software, prototype the core workflow with AI tools. Figure out whether you’re solving a tooling problem or a process problem. Figure out whether you need software at all.This doesn’t mean you’ll build everything internally — of course not. Most of the time, you’ll still end up buying, and that's totally fine, because enterprise tools exist for good reasons (scale, support, security, and maintenance). But now you’ll buy with your eyes wide open.You’ll know what “good” looks like. You’ll show up to demos already understanding the edge cases, and know in about 5 minutes whether they actually get your specific problem. You’ll implement faster. You'll negotiate better because you're not completely dependent on the vendor's solution. And you’ll choose it because it's genuinely better than what you could build yourself.You'll have already mapped out the shape of what you need, and you'll just be looking for the best version of it.The new paradigmFor years, the mantra was: Build or buy.Now, it’s more elegant and way smarter: Build to learn what to buy.And it's not some future state. This is already happening. Right now, somewhere, a customer rep is using AI to fix a product issue they spotted minutes ago. Somewhere else, a finance team is prototyping their own analytical tools because they've realized they can iterate faster than they can write up requirements for engineering. Somewhere, a team is realizing that the boundary between technical and non-technical was always more cultural than fundamental.The companies that embrace this shift will move faster and spend smarter. They’ll know their operations more deeply than any vendor ever could. They'll make fewer expensive mistakes, and buy better tools because they actually understand what makes tools good.The companies that stick to the old playbook will keep sitting through vendor pitches, nodding along at budget-friendly proposals. They’ll debate timelines, and keep mistaking professional decks for actual solutions.Until someone on their own team pops open their laptop, says, “I built a version of this last night. Want to check it out?,” and shows them something they built in two hours that does 80% of what they’re about to pay six figures for.And, just like that, the rules change for good.Siqi Chen is co-founder and CEO of Runway. Read more from our guest writers. Or, consider submitting a post of your own! See our guidelines here.
