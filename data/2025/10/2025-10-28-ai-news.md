# AI News for 2025-10-28 (Asia/Taipei)

Collected 8 article(s).

- [Finding return on AI investments across industries](https://www.technologyreview.com/2025/10/28/1126693/finding-return-on-ai-investments-across-industries/) — 23:00 · MIT Technology Review (AI)
  > The market is officially three years post ChatGPT and many of the pundit bylines have shifted to using terms like “bubble” to suggest reasons behind generative AI not realizing material returns outside a handful of technology suppliers.  In September, the MIT NANDA report made waves because the soundbite every author and influencer picked up on…
- [The Download: Microsoft’s stance on erotic AI, and an AI hype mystery](https://www.technologyreview.com/2025/10/28/1126802/the-download-microsofts-stance-on-erotic-ai-and-an-ai-hype-mystery/) — 21:10 · MIT Technology Review (AI)
  > This is today’s edition of The Download, our weekday newsletter that provides a daily dose of what’s going on in the world of technology. “We will never build a sex robot,” says Mustafa Suleyman Mustafa Suleyman, CEO of Microsoft AI, is trying to walk a fine line. On the one hand, he thinks that the industry is…
- [Intuit learned to build AI agents for finance the hard way: Trust lost in buckets, earned back in spoonfuls](https://venturebeat.com/ai/intuit-learned-to-build-ai-agents-for-finance-the-hard-way-trust-lost-in) — 20:30 · VentureBeat AI
  > Building AI for financial software requires a different playbook than consumer AI, and Intuit's latest QuickBooks release provides an example.The company has announced Intuit Intelligence, a system that orchestrates specialized AI agents across its QuickBooks platform to handle tasks including sales tax compliance and payroll processing. These new agents augment existing accounting and project management agents (which have also been updated) as well as a unified interface that lets users query data across QuickBooks, third-party systems and uploaded files using natural language. The new development follow years of investment and improvement in Intuit's GenOS, allowing the company to build AI capabilities that reduce latency and improve accuracy.But the real news isn't what Intuit built — it's how they built it and why their design decisions will make AI more usable. The company's latest AI rollout represents an evolution built on hard-won lessons about what works and what doesn't when deploying AI in financial contexts.What the company learned is sobering: Even when its accounting agent improved transaction categorization accuracy by 20 percentage points on average, they still received complaints about errors."The use cases that we're trying to solve for customers include tax and finance; if you make a mistake in this world, you lose trust with customers in buckets and we only get it back in spoonfuls," Joe Preston, Intuit's VP of product and design, told VentureBeat.The architecture of trust: Real data queries over generative responsesIntuit's technical strategy centers on a fundamental design decision. For financial queries and business intelligence, the system queries actual data, rather than generating responses through large language models (LLMs).Also critically important: That data isn't all in one place. Intuit's technical implementation allows QuickBooks to ingest data from multiple distinct sources: native Intuit data, OAuth-connected third-party systems like Square for payments and user-uploaded files such as spreadsheets containing vendor pricing lists or marketing campaign data. This creates a unified data layer that AI agents can query reliably."We're actually querying your real data," Preston explained. "That's very different than if you were to just copy, paste out a spreadsheet or a PDF and paste into ChatGPT."This architectural choice means that the Intuit Intelligence system functions more as an orchestration layer. It's a natural language interface to structured data operations. When a user asks about projected profitability or wants to run payroll, the system translates the natural language query into database operations against verified financial data.This matters because Intuit's internal research has uncovered widespread shadow AI usage. When surveyed, 25% of accountants using QuickBooks admitted they were already copying and pasting data into ChatGPT or Google Gemini for analysis.Intuit's approach treats AI as a query translation and orchestration mechanism, not a content generator. This reduces the hallucination risk that has plagued AI deployments in financial contexts.Explainability as a design requirement, not an afterthoughtBeyond the technical architecture, Intuit has made explainability a core user experience across its AI agents. This goes beyond simply providing correct answers: It means showing users the reasoning behind automated decisions.When Intuit's accounting agent categorizes a transaction, it doesn't just display the result; it shows the reasoning. This isn't marketing copy about explainable AI, it's actual UI displaying data points and logic."It's about closing that trust loop and making sure customers understand the why," Alastair Simpson, Intuit's VP of design, told VentureBeat.This becomes particularly critical when you consider Intuit's user research: While half of small businesses describe AI as helpful, nearly a quarter haven't used AI at all. The explanation layer serves both populations: Building confidence for newcomers, while giving experienced users the context to verify accuracy.The design also enforces human control at critical decision points. This approach extends beyond the interface. Intuit connects users directly with human experts, embedded in the same workflows, when automation reaches its limits or when users want validation.Navigating the transition from forms to conversationsOne of Intuit's more interesting challenges involves managing a fundamental shift in user interfaces. Preston described it as having one foot in the past and one foot in the future."This isn't just Intuit, this is the market as a whole," said Preston. "Today we still have a lot of customers filling out forms and going through tables full of data. We're investing a lot into leaning in and questioning the ways that we do it across our products today, where you're basically just filling out, form after form, or table after table, because we see where the world is headed, which is really a different form of interacting with these products."This creates a product design challenge: How do you serve users who are comfortable with traditional interfaces while gradually introducing conversational and agentic capabilities?Intuit's approach has been to embed AI agents directly into existing workflows. This means not forcing users to adopt entirely new interaction patterns. The payments agent appears alongside invoicing workflows; the accounting agent enhances the existing reconciliation process rather than replacing it. This incremental approach lets users experience AI benefits without abandoning familiar processes.What enterprise AI builders can learn from Intuit's approachIntuit's experience deploying AI in financial contexts surfaces several principles that apply broadly to enterprise AI initiatives. Architecture matters for trust: In domains where accuracy is critical, consider whether you need content generation or data query translation. Intuit's decision to treat AI as an orchestration and natural language interface layer dramatically reduces hallucination risk and avoids using AI as a generative system.Explainability must be designed in, not bolted on: Showing users why the AI made a decision isn't optional when trust is at stake. This requires deliberate UX design. It may constrain model choices.User control preserves trust during accuracy improvements: Intuit's accounting agent improved categorization accuracy by 20 percentage points. Yet, maintaining user override capabilities was essential for adoption.Transition gradually from familiar interfaces: Don't force users to abandon forms for conversations. Embed AI capabilities into existing workflows first. Let users experience benefits before asking them to change behavior.Be honest about what's reactive versus proactive: Current AI agents primarily respond to prompts and automate defined tasks. True proactive intelligence that makes unprompted strategic recommendations remains an evolving capability. Address workforce concerns with tooling, not just messaging: If AI is meant to augment rather than replace workers, provide workers with AI tools. Show them how to leverage the technology.For enterprises navigating AI adoption, Intuit's journey offers a clear directive. The winning approach prioritizes trustworthiness over capability demonstrations. In domains where mistakes have real consequences, that means investing in accuracy, transparency and human oversight before pursuing conversational sophistication or autonomous action.Simpson frames the challenge succinctly: "We didn't want it to be a bolted-on layer. We wanted customers to be in their natural workflow, and have agents doing work for customers, embedded in the workflow."
- [“We will never build a sex robot,” says Mustafa Suleyman](https://www.technologyreview.com/2025/10/28/1126781/we-will-never-build-a-sex-robot-says-mustafa-suleyman/) — 19:07 · MIT Technology Review (AI)
  > Mustafa Suleyman, CEO of Microsoft AI, is trying to walk a fine line. On the one hand, he thinks that the industry is taking AI in a dangerous direction by building chatbots that present as human: He worries that people will be tricked into seeing life instead of lifelike behavior. In August, he published a…
- [An AI adoption riddle](https://www.technologyreview.com/2025/10/28/1126687/an-ai-adoption-riddle/) — 17:00 · MIT Technology Review (AI)
  > A few weeks ago, I set out on what I thought would be a straightforward reporting journey.  After years of momentum for AI—even if you didn’t think it would be good for the world, you probably thought it was powerful enough to take seriously—hype for the technology had been slightly punctured. First there was the…
- [PayPal’s agentic commerce play shows why flexibility, not standards, will define the eext c-commerce wave](https://venturebeat.com/ai/paypals-agentic-commerce-play-shows-why-flexibility-not-standards-will) — 12:00 · VentureBeat AI
  > Enterprises looking to sell goods and services online are waiting for the backbone of agentic commerce to be hashed out; but PayPal is hoping its new features will bridge the gap.The payments company is launching a discoverability solution that allows enterprises to make its product available on any chat platform, regardless of the model or agent payment protocol. PayPal, which is a participant in Google’s Agent Payments Protocol (AP2), found that it can leverage its relationship with merchants and enterprises to help pave the way for an easier transition into agentic commerce and offer flexibility that will benefit the ecosystem. Michelle Gill, PayPal's GM for small business and financial services, told VentureBeat that AI-powered shopping will continue to grow, so enterprises and brands must begin laying the groundwork early. “We think that merchants who've historically sold through web stores, particularly in the e-commerce space, are really going to need a way to get active on all of these large language models (LLMs),” Gill said. “The challenge is that no one really knows how fast all of this is going to move. We’re trying to help merchants think through how to do all of this as low-touch as possible while using the infrastructure they already have without doing a bazillion integrations.”She added that AI shopping would also bring about “a resurgence from consumers trying to ensure their investment is protected.”PayPal partnered with website builder Wix, Cymbio, Commerce and Shopware to bring products to chat platforms like Perplexity. 
Agent-powered shopping PayPal’s Agentic Commerce Services include two features. The first is Agent Ready, which would allow existing PayPal merchants to accept payments on AI platforms. The second is Shop Sync, which will enable companies’ product data to be discoverable through different AI chat interfaces. It takes a company’s catalog information and plug its inventory and fulfillment data to chat platforms. Gill said the data goes into a central repository where AI models can ingest the information. Right now, companies can access Shop Sync; Agent Ready is coming in 2026. Gill said Agentic Commerce Services is a one-to-many solution that would be helpful right now, as different LLMs scrape different data sources to surface information. Other benefits include:Fast integration with current and future partners;More product discovery over the traditional search, browse and cart experiences;Preserved customer insights and relationships where the brand continues to have control over their records and communications with customers. Right now, the service is only available through Perplexity, but Gill said more platforms will be added soon. Fragmented AI platforms 
Agentic commerce is still very much in the early stages. AI agents are just beginning to get better at reading a browser. while platforms like ChatGPT, Gemini and Perplexity can now surface products and services based on user queries, people cannot technically buy things from chat (yet).There’s a race right now to create a standard to enable agents to transact on behalf of users. Other than Google’s AP2, OpenAI and Stripe have the Agentic Commerce Protocol (ACP), and Visa recently launched its Trusted Agent Protocol. Beyond enabling a trust layer for agents to transact, enterprises struggle with fragmentation in agentic commerce. Different chat platforms use different models, which also interpret information in slightly different ways. Gill said PayPal learned that when it comes to working with merchants, flexibility is critical. “How do you decide if you're going to spend your time integrating with Google, Microsoft, ChatGPT or Perplexity?" Gill noted. "And each one of them right now has a different protocol, a different catalog, config, a different everything. That is a lot of time to make a bet as to where you should spend your time."
- [MiniMax-M2 is the new king of open source LLMs (especially for agentic tool calling)](https://venturebeat.com/ai/minimax-m2-is-the-new-king-of-open-source-llms-especially-for-agentic-tool) — 03:01 · VentureBeat AI
  > Watch out, DeepSeek and Qwen! There's a new king of open source large language models (LLMs), especially when it comes to something enterprises are increasingly valuing: agentic tool use — that is, the ability to go off and use other software capabilities like web search or bespoke applications — without much human guidance. That model is none other than MiniMax-M2, the latest LLM from the Chinese startup of the same name. And in a big win for enterprises globally, the model is available under a permissive, enterprise-friendly MIT License, meaning it is made available freely for developers to take, deploy, retrain, and use how they see fit — even for commercial purposes. It can be found on Hugging Face, GitHub and ModelScope, as well as through MiniMax's API here. It supports OpenAI and Anthropic API standards, as well, making it easy for customers of said proprietary AI startups to shift out their models to MiniMax's API, if they want.According to independent evaluations by Artificial Analysis, a third-party generative AI model benchmarking and research organization, M2 now ranks first among all open-weight systems worldwide on the Intelligence Index—a composite measure of reasoning, coding, and task-execution performance. In agentic benchmarks that measure how well a model can plan, execute, and use external tools—skills that power coding assistants and autonomous agents—MiniMax’s own reported results, following the Artificial Analysis methodology, show τ²-Bench 77.2, BrowseComp 44.0, and FinSearchComp-global 65.5. These scores place it at or near the level of top proprietary systems like GPT-5 (thinking) and Claude Sonnet 4.5, making MiniMax-M2 the highest-performing open model yet released for real-world agentic and tool-calling tasks.What It Means For Enterprises and the AI RaceBuilt around an efficient Mixture-of-Experts (MoE) architecture, MiniMax-M2 delivers high-end capability for agentic and developer workflows while remaining practical for enterprise deployment.For technical decision-makers, the release marks an important turning point for open models in business settings. MiniMax-M2 combines frontier-level reasoning with a manageable activation footprint—just 10 billion active parameters out of 230 billion total. This design enables enterprises to operate advanced reasoning and automation workloads on fewer GPUs, achieving near-state-of-the-art results without the infrastructure demands or licensing costs associated with proprietary frontier systems.Artificial Analysis’ data show that MiniMax-M2’s strengths go beyond raw intelligence scores. The model leads or closely trails top proprietary systems such as GPT-5 (thinking) and Claude Sonnet 4.5 across benchmarks for end-to-end coding, reasoning, and agentic tool use. Its performance in τ²-Bench, SWE-Bench, and BrowseComp indicates particular advantages for organizations that depend on AI systems capable of planning, executing, and verifying complex workflows—key functions for agentic and developer tools inside enterprise environments.As LLM engineer Pierre-Carl Langlais aka Alexander Doria posted on X: "MiniMax [is] making a case for mastering the technology end-to-end to get actual agentic automation."Compact Design, Scalable PerformanceMiniMax-M2’s technical architecture is a sparse Mixture-of-Experts model with 230 billion total parameters and 10 billion active per inference. This configuration significantly reduces latency and compute requirements while maintaining broad general intelligence. The design allows for responsive agent loops—compile–run–test or browse–retrieve–cite cycles—that execute faster and more predictably than denser models.For enterprise technology teams, this means easier scaling, lower cloud costs, and reduced deployment friction. According to Artificial Analysis, the model can be served efficiently on as few as four NVIDIA H100 GPUs at FP8 precision, a setup well within reach for mid-size organizations or departmental AI clusters.Benchmark Leadership Across Agentic and Coding WorkflowsMiniMax’s benchmark suite highlights strong real-world performance across developer and agent environments. The figure below, released with the model, compares MiniMax-M2 (in red) with several leading proprietary and open models, including GPT-5 (thinking), Claude Sonnet 4.5, Gemini 2.5 Pro, and DeepSeek-V3.2.MiniMax-M2 achieves top or near-top performance in many categories:SWE-bench Verified: 69.4 — close to GPT-5’s 74.9ArtifactsBench: 66.8 — above Claude Sonnet 4.5 and DeepSeek-V3.2τ²-Bench: 77.2 — approaching GPT-5’s 80.1GAIA (text only): 75.7 — surpassing DeepSeek-V3.2BrowseComp: 44.0 — notably stronger than other open modelsFinSearchComp-global: 65.5 — best among tested open-weight systemsThese results show MiniMax-M2’s capability in executing complex, tool-augmented tasks across multiple languages and environments—skills increasingly relevant for automated support, R&D, and data analysis inside enterprises.Strong Showing in Artificial Analysis’ Intelligence IndexThe model’s overall intelligence profile is confirmed in the latest Artificial Analysis Intelligence Index v3.0, which aggregates performance across ten reasoning benchmarks including MMLU-Pro, GPQA Diamond, AIME 2025, IFBench, and τ²-Bench Telecom.MiniMax-M2 scored 61 points, ranking as the highest open-weight model globally and following closely behind GPT-5 (high) and Grok 4. Artificial Analysis highlighted the model’s balance between technical accuracy, reasoning depth, and applied intelligence across domains. For enterprise users, this consistency indicates a reliable model foundation suitable for integration into software engineering, customer support, or knowledge automation systems.Designed for Developers and Agentic SystemsMiniMax engineered M2 for end-to-end developer workflows, enabling multi-file code edits, automated testing, and regression repair directly within integrated development environments or CI/CD pipelines. The model also excels in agentic planning—handling tasks that combine web search, command execution, and API calls while maintaining reasoning traceability.These capabilities make MiniMax-M2 especially valuable for enterprises exploring autonomous developer agents, data analysis assistants, or AI-augmented operational tools. Benchmarks such as Terminal-Bench and BrowseComp demonstrate the model’s ability to adapt to incomplete data and recover gracefully from intermediate errors, improving reliability in production settings.Interleaved Thinking and Structured Tool UseA distinctive aspect of MiniMax-M2 is its interleaved thinking format, which maintains visible reasoning traces between ... tags.This enables the model to plan and verify steps across multiple exchanges, a critical feature for agentic reasoning. MiniMax advises retaining these segments when passing conversation history to preserve the model’s logic and continuity.The company also provides a Tool Calling Guide on Hugging Face, detailing how developers can connect external tools and APIs via structured XML-style calls. This functionality allows MiniMax-M2 to serve as the reasoning core for larger agent frameworks, executing dynamic tasks such as search, retrieval, and computation through external functions.Open Source Access and Enterprise Deployment OptionsEnterprises can access the model through the MiniMax Open Platform API and MiniMax Agent interface (a web chat similar to ChatGPT), both currently free for a limited time.MiniMax recommends SGLang and vLLM for efficient serving, each offering day-one support for the model’s unique interleaved reasoning and tool-calling structure. Deployment guides and parameter configurations are available through MiniMax’s documentation.Cost Efficiency and Token EconomicsAs Artificial Analysis noted, MiniMax’s API pricing is set at $0.30 per million input tokens and $1.20 per million output tokens, among the most competitive in the open-model ecosystem. ProviderModel (doc link)Input $/1MOutput $/1MNotesMiniMaxMiniMax-M2$0.30$1.20Listed under “Chat Completion v2” for M2. OpenAIGPT-5$1.25$10.00Flagship model pricing on OpenAI’s API pricing page. OpenAIGPT-5 mini$0.25$2.00Cheaper tier for well-defined tasks. AnthropicClaude Sonnet 4.5$3.00$15.00Anthropic’s current per-MTok list; long-context (>200K input) uses a premium tier. GoogleGemini 2.5 Flash (Preview)$0.30$2.50Prices include “thinking tokens”; page also lists cheaper Flash-Lite and 2.0 tiers. xAIGrok-4 Fast (reasoning)$0.20$0.50“Fast” tier; xAI also lists Grok-4 at $3 / $15. DeepSeekDeepSeek-V3.2 (chat)$0.28$0.42Cache-hit input is $0.028; table shows per-model details. Qwen (Alibaba)qwen-flash (Model Studio)from $0.022from $0.216Tiered by input size (≤128K, ≤256K, ≤1M tokens); listed “Input price / Output price per 1M”. CohereCommand R+ (Aug 2024)$2.50$10.00First-party pricing page also lists Command R ($0.50 / $1.50) and others. Notes & caveats (for readers):Prices are USD per million tokens and can change; check linked pages for updates and region/endpoint nuances (e.g., Anthropic long-context >200K input, Google Live API variants, cache discounts). Vendors may bill extra for server-side tools (web search, code execution) or offer batch/context-cache discounts. While the model produces longer, more explicit reasoning traces, its sparse activation and optimized compute design help maintain a favorable cost-performance balance—an advantage for teams deploying interactive agents or high-volume automation systems.Background on MiniMax — an Emerging Chinese PowerhouseMiniMax has quickly become one of the most closely watched names in China’s fast-rising AI sector. Backed by Alibaba and Tencent, the company moved from relative obscurity to international recognition within a year—first through breakthroughs in AI video generation, then through a series of open-weight large language models (LLMs) aimed squarely at developers and enterprises.The company first captured global attention in late 2024 with its AI video generation tool, “video-01,” which demonstrated the ability to create dynamic, cinematic scenes in seconds. VentureBeat described how the model’s launch sparked widespread interest after online creators began sharing lifelike, AI-generated footage—most memorably, a viral clip of a Star Wars lightsaber duel that drew millions of views in under two days. CEO Yan Junjie emphasized that the system outperformed leading Western tools in generating human movement and expression, an area where video AIs often struggle. The product, later commercialized through MiniMax’s Hailuo platform, showcased the startup’s technical confidence and creative reach, helping to establish China as a serious contender in generative video technology.By early 2025, MiniMax had turned its attention to long-context language modeling, unveiling the MiniMax-01 series, including MiniMax-Text-01 and MiniMax-VL-01. These open-weight models introduced an unprecedented 4-million-token context window, doubling the reach of Google’s Gemini 1.5 Pro and dwarfing OpenAI’s GPT-4o by more than twentyfold. The company continued its rapid cadence with the MiniMax-M1 release in June 2025, a model focused on long-context reasoning and reinforcement learning efficiency. M1 extended context capacity to 1 million tokens and introduced a hybrid Mixture-of-Experts design trained using a custom reinforcement-learning algorithm known as CISPO. Remarkably, VentureBeat reported that MiniMax trained M1 at a total cost of about $534,700, roughly one-tenth of DeepSeek’s R1 and far below the multimillion-dollar budgets typical for frontier-scale models. For enterprises and technical teams, MiniMax’s trajectory signals the arrival of a new generation of cost-efficient, open-weight models designed for real-world deployment. Its open licensing—ranging from Apache 2.0 to MIT—gives businesses freedom to customize, self-host, and fine-tune without vendor lock-in or compliance restrictions. Features such as structured function calling, long-context retention, and high-efficiency attention architectures directly address the needs of engineering groups managing multi-step reasoning systems and data-intensive pipelines.As MiniMax continues to expand its lineup, the company has emerged as a key global innovator in open-weight AI, combining ambitious research with pragmatic engineering. Open-Weight Leadership and Industry ContextThe release of MiniMax-M2 reinforces the growing leadership of Chinese AI research groups in open-weight model development. Following earlier contributions from DeepSeek, Alibaba’s Qwen series, and Moonshot AI, MiniMax’s entry continues the trend toward open, efficient systems designed for real-world use. Artificial Analysis observed that MiniMax-M2 exemplifies a broader shift in focus toward agentic capability and reinforcement-learning refinement, prioritizing controllable reasoning and real utility over raw model size.For enterprises, this means access to a state-of-the-art open model that can be audited, fine-tuned, and deployed internally with full transparency. By pairing strong benchmark performance with open licensing and efficient scaling, MiniMaxAI positions MiniMax-M2 as a practical foundation for intelligent systems that think, act, and assist with traceable logic—making it one of the most enterprise-ready open AI models available today.
- [Anthropic rolls out Claude AI for finance, integrates with Excel to rival Microsoft Copilot](https://venturebeat.com/ai/anthropic-rolls-out-claude-ai-for-finance-integrates-with-excel-to-rival) — 00:00 · VentureBeat AI
  > Anthropic is making its most aggressive push yet into the trillion-dollar financial services industry, unveiling a suite of tools that embed its Claude AI assistant directly into Microsoft Excel and connect it to real-time market data from some of the world's most influential financial information providers.The San Francisco-based AI startup announced Monday it is releasing Claude for Excel, allowing financial analysts to interact with the AI system directly within their spreadsheets — the quintessential tool of modern finance. Beyond Excel, select Claude models are also being made available in Microsoft Copilot Studio and Researcher agent, expanding the integration across Microsoft's enterprise AI ecosystem. The integration marks a significant escalation in Anthropic's campaign to position itself as the AI platform of choice for banks, asset managers, and insurance companies, markets where precision and regulatory compliance matter far more than creative flair.The expansion comes just three months after Anthropic launched its Financial Analysis Solution in July, and it signals the company's determination to capture market share in an industry projected to spend $97 billion on AI by 2027, up from $35 billion in 2023.More importantly, it positions Anthropic to compete directly with Microsoft — ironically, its partner in this Excel integration — which has its own Copilot AI assistant embedded across its Office suite, and with OpenAI, which counts Microsoft as its largest investor.Why Excel has become the new battleground for AI in financeThe decision to build directly into Excel is hardly accidental. Excel remains the lingua franca of finance, the digital workspace where analysts spend countless hours constructing financial models, running valuations, and stress-testing assumptions. By embedding Claude into this environment, Anthropic is meeting financial professionals exactly where they work rather than asking them to toggle between applications.Claude for Excel allows users to work with the AI in a sidebar where it can read, analyze, modify, and create new Excel workbooks while providing full transparency about the actions it takes by tracking and explaining changes and letting users navigate directly to referenced cells.This transparency feature addresses one of the most persistent anxieties around AI in finance: the "black box" problem. When billions of dollars ride on a financial model's output, analysts need to understand not just the answer but how the AI arrived at it. By showing its work at the cell level, Anthropic is attempting to build the trust necessary for widespread adoption in an industry where careers and fortunes can turn on a misplaced decimal point.The technical implementation is sophisticated. Claude can discuss how spreadsheets work, modify them while preserving formula dependencies — a notoriously complex task — debug cell formulas, populate templates with new data, or build entirely new spreadsheets from scratch. This isn't merely a chatbot that answers questions about your data; it's a collaborative tool that can actively manipulate the models that drive investment decisions worth trillions of dollars.How Anthropic is building data moats around its financial AI platformPerhaps more significant than the Excel integration is Anthropic's expansion of its connector ecosystem, which now links Claude to live market data and proprietary research from financial information giants. The company added six major new data partnerships spanning the entire spectrum of financial information that professional investors rely upon.Aiera now provides Claude with real-time earnings call transcripts and summaries of investor events like shareholder meetings, presentations, and conferences. The Aiera connector also enables a data feed from Third Bridge, which gives Claude access to a library of insights interviews, company intelligence, and industry analysis from experts and former executives. Chronograph gives private equity investors operational and financial information for portfolio monitoring and conducting due diligence, including performance metrics, valuations, and fund-level data.Egnyte enables Claude to securely search permitted data for internal data rooms, investment documents, and approved financial models while maintaining governed access controls. LSEG, the London Stock Exchange Group, connects Claude to live market data including fixed income pricing, equities, foreign exchange rates, macroeconomic indicators, and analysts' estimates of other important financial metrics. Moody's provides access to proprietary credit ratings, research, and company data covering ownership, financials, and news on more than 600 million public and private companies, supporting work and research in compliance, credit analysis, and business development. MT Newswires provides Claude with access to the latest global multi-asset class news on financial markets and economies.These partnerships amount to a land grab for the informational infrastructure that powers modern finance. Previously announced in July, Anthropic had already secured integrations with S&P Capital IQ, Daloopa, Morningstar, FactSet, PitchBook, Snowflake, and Databricks. Together, these connectors give Claude access to virtually every category of financial data an analyst might need: fundamental company data, market prices, credit assessments, private company intelligence, alternative data, and breaking news.This matters because the quality of AI outputs depends entirely on the quality of inputs. Generic large language models trained on public internet data simply cannot compete with systems that have direct pipelines to Bloomberg-quality financial information. By securing these partnerships, Anthropic is building moats around its financial services offering that competitors will find difficult to replicate.The strategic calculus here is clear: Anthropic is betting that domain-specific AI systems with privileged access to proprietary data will outcompete general-purpose AI assistants. It's a direct challenge to the "one AI to rule them all" approach favored by some competitors.Pre-configured workflows target the daily grind of Wall Street analystsThe third pillar of Anthropic's announcement involves six new "Agent Skills" — pre-configured workflows for common financial tasks. These skills are Anthropic's attempt to productize the workflows of entry-level and mid-level financial analysts, professionals who spend their days building models, processing due diligence documents, and writing research reports. Anthropic has designed skills specifically to automate these time-consuming tasks.The new skills include building discounted cash flow models complete with full free cash flow projections, weighted average cost of capital calculations, scenario toggles, and sensitivity tables. There's comparable company analysis featuring valuation multiples and operating metrics that can be easily refreshed with updated data. Claude can now process data room documents into Excel spreadsheets populated with financial information, customer lists, and contract terms. It can create company teasers and profiles for pitch books and buyer lists, perform earnings analyses that use quarterly transcripts and financials to extract important metrics, guidance changes, and management commentary, and produce initiating coverage reports with industry analysis, company deep dives, and valuation frameworks.It's worth noting that Anthropic's Sonnet 4.5 model now tops the Finance Agent benchmark from Vals AI at 55.3% accuracy, a metric designed to test AI systems on tasks expected of entry-level financial analysts. A 55% accuracy rate might sound underwhelming, but it is state-of-the-art performance and highlights both the promise and limitations of AI in finance. The technology can clearly handle sophisticated analytical tasks, but it's not yet reliable enough to operate autonomously without human oversight — a reality that may actually reassure both regulators and the analysts whose jobs might otherwise be at risk.The Agent Skills approach is particularly clever because it packages AI capabilities in terms that financial institutions already understand. Rather than selling generic "AI assistance," Anthropic is offering solutions to specific, well-defined problems: "You need a DCF model? We have a skill for that. You need to analyze earnings calls? We have a skill for that too."Trillion-dollar clients are already seeing massive productivity gainsAnthropic's financial services strategy appears to be gaining traction with exactly the kind of marquee clients that matter in enterprise sales. The company counts among its clients AIA Labs at Bridgewater, Commonwealth Bank of Australia, American International Group, and Norges Bank Investment Management — Norway's $1.6 trillion sovereign wealth fund, one of the world's largest institutional investors.NBIM CEO Nicolai Tangen reported achieving approximately 20% productivity gains, equivalent to 213,000 hours, with portfolio managers and risk departments now able to "seamlessly query our Snowflake data warehouse and analyze earnings calls with unprecedented efficiency."At AIG, CEO Peter Zaffino said the partnership has "compressed the timeline to review business by more than 5x in our early rollouts while simultaneously improving our data accuracy from 75% to over 90%." If these numbers hold across broader deployments, the productivity implications for the financial services industry are staggering.These aren't pilot programs or proof-of-concept deployments; they're production implementations at institutions managing trillions of dollars in assets and making underwriting decisions that affect millions of customers. Their public endorsements provide the social proof that typically drives enterprise adoption in conservative industries.Regulatory uncertainty creates both opportunity and risk for AI deploymentYet Anthropic's financial services ambitions unfold against a backdrop of heightened regulatory scrutiny and shifting enforcement priorities. In 2023, the Consumer Financial Protection Bureau released guidance requiring lenders to "use specific and accurate reasons when taking adverse actions against consumers" involving AI, and issued additional guidance requiring regulated entities to "evaluate their underwriting models for bias" and "evaluate automated collateral-valuation and appraisal processes in ways that minimize bias."However, according to a Brookings Institution analysis, these measures have since been revoked with work stopped or eliminated at the current downsized CFPB under the current administration, creating regulatory uncertainty. The pendulum has swung from the Biden administration's cautious approach, exemplified by an executive order on safe AI development, toward the Trump administration's "America's AI Action Plan," which seeks to "cement U.S. dominance in artificial intelligence" through deregulation.This regulatory flux creates both opportunities and risks. Financial institutions eager to deploy AI now face less prescriptive federal oversight, potentially accelerating adoption. But the absence of clear guardrails also exposes them to potential liability if AI systems produce discriminatory outcomes, particularly in lending and underwriting.The Massachusetts Attorney General recently reached a $2.5 million settlement with student loan company Earnest Operations, alleging that its use of AI models resulted in "disparate impact in approval rates and loan terms, specifically disadvantaging Black and Hispanic applicants." Such cases will likely multiply as AI deployment grows, creating a patchwork of state-level enforcement even as federal oversight recedes.Anthropic appears acutely aware of these risks. In an interview with Banking Dive, Jonathan Pelosi, Anthropic's global head of industry for financial services, emphasized that Claude requires a "human in the loop." The platform, he said, is not intended for autonomous financial decision-making or to provide stock recommendations that users follow blindly. During client onboarding, Pelosi told the publication, Anthropic focuses on training and understanding model limitations, putting guardrails in place so people treat Claude as a helpful technology rather than a replacement for human judgment.Competition heats up as every major tech company targets finance AIAnthropic's financial services push comes as AI competition intensifies across the enterprise. OpenAI, Microsoft, Google, and numerous startups are all vying for position in what may become one of AI's most lucrative verticals. Goldman Sachs introduced a generative AI assistant to its bankers, traders, and asset managers in January, signaling that major banks may build their own capabilities rather than rely exclusively on third-party providers.The emergence of domain-specific AI models like BloombergGPT — trained specifically on financial data — suggests the market may fragment between generalized AI assistants and specialized tools. Anthropic's strategy appears to stake out a middle ground: general-purpose models, since Claude was not trained exclusively on financial data, enhanced with financial-specific tooling, data access, and workflows.The company's partnership strategy with implementation consultancies including Deloitte, KPMG, PwC, Slalom, TribeAI, and Turing is equally critical. These firms serve as force multipliers, embedding Anthropic's technology into their own service offerings and providing the change management expertise that financial institutions need to successfully adopt AI at scale.CFOs worry about AI hallucinations and cascading errorsThe broader question is whether AI tools like Claude will genuinely transform financial services productivity or merely shift work around. The PYMNTS Intelligence report "The Agentic Trust Gap" found that chief financial officers remain hesitant about AI agents, with "nagging concern" about hallucinations where "an AI agent can go off script and expose firms to cascading payment errors and other inaccuracies.""For finance leaders, the message is stark: Harness AI's momentum now, but build the guardrails before the next quarterly call—or risk owning the fallout," the report warned.A 2025 KPMG report found that 70% of board members have developed responsible use policies for employees, with other popular initiatives including implementing a recognized AI risk and governance framework, developing ethical guidelines and training programs for AI developers, and conducting regular AI use audits.The financial services industry faces a delicate balancing act: move too slowly and risk competitive disadvantage as rivals achieve productivity gains; move too quickly and risk operational failures, regulatory penalties, or reputational damage. Speaking at the Evident AI Symposium in New York last week, Ian Glasner, HSBC's group head of emerging technology, innovation and ventures, struck an optimistic tone about the sector's readiness for AI adoption. "As an industry, we are very well prepared to manage risk," he said, according to CIO Dive. "Let's not overcomplicate this. We just need to be focused on the business use case and the value associated."Anthropic's latest moves suggest the company sees financial services as a beachhead market where AI's value proposition is clear, customers have deep pockets, and the technical requirements play to Claude's strengths in reasoning and accuracy. By building Excel integration, securing data partnerships, and pre-packaging common workflows, Anthropic is reducing the friction that typically slows enterprise AI adoption.The $61.5 billion valuation the company commanded in its March fundraising round — up from roughly $16 billion a year earlier — suggests investors believe this strategy will work. But the real test will come as these tools move from pilot programs to production deployments across thousands of analysts and billions of dollars in transactions.Financial services may prove to be AI's most demanding proving ground: an industry where mistakes are costly, regulation is stringent, and trust is everything. If Claude can successfully navigate the spreadsheet cells and data feeds of Wall Street without hallucinating a decimal point in the wrong direction, Anthropic will have accomplished something far more valuable than winning another benchmark test. It will have proven that AI can be trusted with the money.
