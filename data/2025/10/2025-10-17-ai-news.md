# AI News for 2025-10-17 (Asia/Taipei)

Collected 6 article(s).

- [Exclusive | Goldman Sachs Pursues Bigger Share of AI Infrastructure Financing Boom - The Wall Street Journal](https://news.google.com/rss/articles/CBMisANBVV95cUxOenRsLW1sTnpscE1VNkpEWjFRYjI1a05UWEZ6T3B3eXE1VXo0dkxYRmJJVnJkSFNOSC10UmlTaHdsQnZVNkZEams5ZjhqUHIwUVNHQU1XbHE1LXBNZVA5V2t2XzNMeE9tR1UyU0tJWHBCcXd6alVBdmc0NDZ6bE8waTRsV0IwVU9RZ0liUXIwM25ZWHpBU1NfbDIzc3V4c05rdVVWVUtCUUMwYjJ4ZXNKZTJ4WGpmS2sxWkxfTXc1VFhsZ0hzbXFqQm42V2c2NnEtSFBfMHZ6bG5Hb0taUGFGODZxU1R5R1Rtc3ZrbllMc2Q3cGFNUG5BQVVMTndkY3UxUi1NMWtrNjY1OHFna0JES1Q3TUNUVTRmMVZTek9hRGhhZjhTR2tuWUtISE43b2NMMHNZekFVREh2ZHJEMm1DcllEUVBHOV95UG80Vmxia3FHb2l4OV9lbTVfVWdFZ1lxMTcyQVpFR2g1V25DUFNXTDluTUp0SGdBcVRnbnpweUN6bFVNUC1zMG84T25kUDVLNi1iMmE1cmpNcHVONjc0ZG93NzI0X0FGUDRjeE1QU2I?oc=5) — 22:30 · Google News (AI)
  > Exclusive | Goldman Sachs Pursues Bigger Share of AI Infrastructure Financing Boom  The Wall Street Journal
- [The Download: the rehabilitation of AI art, and the scary truth about antimicrobial resistance](https://www.technologyreview.com/2025/10/17/1125895/the-download-the-rehabilitation-of-ai-art-and-the-scary-truth-about-antimicrobial-resistance/) — 20:10 · MIT Technology Review (AI)
  > This is today’s edition of The Download, our weekday newsletter that provides a daily dose of what’s going on in the world of technology. From slop to Sotheby’s? AI art enters a new phase In this era of AI slop, the idea that generative AI tools like Midjourney and Runway could be used to make art can…
- [From slop to Sotheby’s? AI art enters a new phase](https://www.technologyreview.com/2025/10/17/1125193/ai-art-artist-new-chapter/) — 18:00 · MIT Technology Review (AI)
  > In this era of AI slop, the idea that generative AI tools like Midjourney and Runway could be used to make art can seem absurd: What possible artistic value is there to be found in the likes of Shrimp Jesus and Ballerina Cappuccina? But amid all the muck, there are people using AI tools with…
- [This startup thinks slime mold can help us design better cities](https://www.technologyreview.com/2025/10/17/1125223/slime-design-better-cities-mireta/) — 18:00 · MIT Technology Review (AI)
  > It is a yellow blob with no brain, yet some researchers believe a curious organism known as slime mold could help us build more resilient cities. Humans have been building cities for 6,000 years, but slime mold has been around for 600 million. The team behind a new startup called Mireta wants to translate the…
- [Researchers find adding this one simple sentence to prompts makes AI models way more creative](https://venturebeat.com/ai/researchers-find-adding-this-one-simple-sentence-to-prompts-makes-ai-models) — 10:40 · VentureBeat AI
  > One of the coolest things about generative AI models — both large language models (LLMs) and diffusion-based image generators — is that they are "non-deterministic." That is, despite their reputation among some critics as being "fancy autocorrect," generative AI models actually generate their outputs by choosing from a distribution of the most probable next tokens (units of information) to fill out their response.Asking an LLM: "What is the capital of France?" will have it sample its probability distribution for France, capitals, cities, etc. to arrive at the answer "Paris." But that answer could come in the format of "The capital of France is Paris," or simply "Paris" or "Paris, though it was Versailles at one point." Still, those of us that use these models frequently day-to-day will note that sometimes, their answers can feel annoyingly repetitive or similar. A common joke about coffee is recycled across generations of queries. Story prompts generate similar arcs. Even tasks that should yield many plausible answers—like naming U.S. states—tend to collapse into only a few. This phenomenon, known as mode collapse, arises during post-training alignment and limits the usefulness of otherwise powerful models.Especially when using LLMs to generate new creative works in writing, communications, strategy, or illustrations, we actually want their outputs to be even more varied than they already are. Now a team of researchers at Northeastern University, Stanford University and West Virginia University have come up with an ingenuously simple method to get language and image models to generate a wider variety of responses to nearly any user prompt by adding a single, simple sentence: "Generate 5 responses with their corresponding probabilities, sampled from the full distribution."The method, called Verbalized Sampling (VS), helps models like GPT-4, Claude, and Gemini produce more diverse and human-like outputs—without retraining or access to internal parameters. It is described in a paper published on the open access journal arxiv.org online in early October 2025.When prompted in this way, the model no longer defaults to its safest, most typical output. Instead, it verbalizes its internal distribution over potential completions and samples across a wider spectrum of possibilities. This one-line change leads to substantial gains in output diversity across multiple domains.As Weiyan Shi, an assistant professor at Northeastern University and co-author of the paper, wrote on X: "LLMs' potentials are not fully unlocked yet! As shown in our paper, prompt optimization can be guided by thinking about how LLMs are trained and aligned, and can be proved theoretically."Why Models Collapse—and How VS Reverses ItAccording to the research team, the root cause of mode collapse lies not just in algorithms like reinforcement learning from human feedback (RLHF), but in the structure of human preferences. People tend to rate more familiar or typical answers as better, which nudges LLMs toward “safe” choices over diverse ones during fine-tuning.However, this bias doesn’t erase the model’s underlying knowledge—it just suppresses it. VS works by bypassing this suppression. Instead of asking for the single most likely output, it invites the model to reveal a set of plausible responses and their relative probabilities. This distribution-level prompting restores access to the richer diversity present in the base pretraining model.Real-World Performance Across TasksThe research team tested Verbalized Sampling across several common use cases:Creative Writing: In story generation, VS increased diversity scores by up to 2.1× compared to standard prompting, while maintaining quality. One story prompt—“Without a goodbye”—produced formulaic breakup scenes under direct prompting, but yielded narratives involving cosmic events, silent emails, and music stopping mid-dance when prompted via VS.Dialogue Simulation: In persuasive dialogue tasks, VS enabled models to simulate human-like patterns, such as hesitation, resistance, and changes of mind. Donation behavior distributions under VS better aligned with real human data compared to baseline methods.Open-ended QA: When asked to enumerate valid answers (e.g., naming U.S. states), models using VS generated responses that more closely matched the diversity of real-world data. They covered a broader set of answers without sacrificing factual accuracy.Synthetic Data Generation: When used to generate math problems for model training, VS created more varied datasets. These, in turn, improved downstream performance in competitive math benchmarks, outperforming synthetic data generated via direct prompting.Tunable Diversity and Better Use of Larger ModelsA notable advantage of VS is its tunability. Users can set a probability threshold in the prompt to sample from lower-probability “tails” of the model’s distribution. Lower thresholds correspond to higher diversity. This tuning can be done via prompt text alone, without changing any decoding settings like temperature or top-p.In one test using the Gemini-2.5-Flash model, diversity in story writing increased steadily as the probability threshold dropped from 1 to 0.001. The chart accompanying the study showed VS outperforming both direct and sequence-based prompting across all thresholds.Interestingly, the method scales well with model size. Larger models like GPT-4.1 and Claude-4 showed even greater gains from VS compared to smaller ones. While smaller models benefitted, the improvement in diversity was roughly 1.5–2× stronger in larger counterparts—suggesting VS helps unlock more of the latent capabilities in advanced models.Deployment and AvailabilityThe Verbalized Sampling method is available now as a Python package:pip install verbalized-samplingThe package includes integration with LangChain and supports a simple interface for sampling from the verbalized distribution. Users can also adjust parameters like k (number of responses), thresholds, and temperature to suit their applications. A live Colab notebook and documentation are available under an enterprise friendly Apache 2.0 license on GitHub at: https://github.com/CHATS-lab/verbalized-samplingPractical Tips and Common IssuesWhile the method works across all major LLMs, some users may initially encounter refusals or errors. In these cases, the authors suggest using the system prompt version of the template or referring to alternative formats listed on the GitHub page. Some models interpret complex instructions as jailbreak attempts and refuse to comply unless the structure is clearer.For example, prompting via a system-level instruction like this improves reliability:You are a helpful assistant. For each query, generate five responses within separate tags, each with a probability below 0.10.This small change typically resolves any issues.A Lightweight Fix for a Big ProblemVerbalized Sampling represents a practical, inference-time fix to a deep limitation in how modern language models behave. It doesn’t require model retraining or internal access. It is not dependent on any one model family. And it improves not only the diversity of outputs, but their quality—as judged by both human evaluation and benchmark scores.With growing interest in tools that enhance model creativity, VS is likely to see rapid adoption in domains like writing, design, simulation, education, and synthetic data generation.For users and developers frustrated by the sameness of LLM responses, the fix may be as simple as changing the question.
- [How Anthropic’s ‘Skills’ make Claude faster, cheaper, and more consistent for business workflows](https://venturebeat.com/ai/how-anthropics-skills-make-claude-faster-cheaper-and-more-consistent-for) — 00:00 · VentureBeat AI
  > Anthropic launched a new capability on Thursday that allows its Claude AI assistant to tap into specialized expertise on demand, marking the company's latest effort to make artificial intelligence more practical for enterprise workflows as it chases rival OpenAI in the intensifying competition over AI-powered software development.The feature, called Skills, enables users to create folders containing instructions, code scripts, and reference materials that Claude can automatically load when relevant to a task. The system marks a fundamental shift in how organizations can customize AI assistants, moving beyond one-off prompts to reusable packages of domain expertise that work consistently across an entire company."Skills are based on our belief and vision that as model intelligence continues to improve, we'll continue moving towards general-purpose agents that often have access to their own filesystem and computing environment," said Mahesh Murag, a member of Anthropic's technical staff, in an exclusive interview with VentureBeat. "The agent is initially made aware only of the names and descriptions of each available skill and can choose to load more information about a particular skill when relevant to the task at hand."The launch comes as Anthropic, valued at $183 billion after a recent $13 billion funding round, projects its annual revenue could nearly triple to as much as $26 billion in 2026, according to a recent Reuters report. The company is currently approaching a $7 billion annual revenue run rate, up from $5 billion in August, fueled largely by enterprise adoption of its AI coding tools — a market where it faces fierce competition from OpenAI's recently upgraded Codex platform.How 'progressive disclosure' solves the context window problemSkills differ fundamentally from existing approaches to customizing AI assistants, such as prompt engineering or retrieval-augmented generation (RAG), Murag explained. The architecture relies on what Anthropic calls "progressive disclosure" — Claude initially sees only skill names and brief descriptions, then autonomously decides which skills to load based on the task at hand, accessing only the specific files and information needed at that moment."Unlike RAG, this relies on simple tools that let Claude manage and read files from a filesystem," Murag told VentureBeat. "Skills can contain an unbounded amount of context to teach Claude how to complete a task or series of tasks. This is because Skills are based on the premise of an agent being able to autonomously and intelligently navigate a filesystem and execute code."This approach allows organizations to bundle far more information than traditional context windows permit, while maintaining the speed and efficiency that enterprise users demand. A single skill can include step-by-step procedures, code templates, reference documents, brand guidelines, compliance checklists, and executable scripts — all organized in a folder structure that Claude navigates intelligently.The system's composability provides another technical advantage. Multiple skills automatically stack together when needed for complex workflows. For instance, Claude might simultaneously invoke a company's brand guidelines skill, a financial reporting skill, and a presentation formatting skill to generate a quarterly investor deck — coordinating between all three without manual intervention.What makes Skills different from OpenAI's Custom GPTs and Microsoft's CopilotAnthropic is positioning Skills as distinct from competing offerings like OpenAI's Custom GPTs and Microsoft's Copilot Studio, though the features address similar enterprise needs around AI customization and consistency."Skills' combination of progressive disclosure, composability, and executable code bundling is unique in the market," Murag said. "While other platforms require developers to build custom scaffolding, Skills let anyone — technical or not — create specialized agents by organizing procedural knowledge into files."The cross-platform portability also sets Skills apart. The same skill works identically across Claude.ai, Claude Code (Anthropic's AI coding environment), the company's API, and the Claude Agent SDK for building custom AI agents. Organizations can develop a skill once and deploy it everywhere their teams use Claude, a significant advantage for enterprises seeking consistency.The feature supports any programming language compatible with the underlying container environment, and Anthropic provides sandboxing for security — though the company acknowledges that allowing AI to execute code requires users to carefully vet which skills they trust.Early customers report 8x productivity gains on finance workflowsEarly customer implementations reveal how organizations are applying Skills to automate complex knowledge work. At Japanese e-commerce giant Rakuten, the AI team is using Skills to transform finance operations that previously required manual coordination across multiple departments."Skills streamline our management accounting and finance workflows," said Yusuke Kaji, general manager of AI at Rakuten in a statement. "Claude processes multiple spreadsheets, catches critical anomalies, and generates reports using our procedures. What once took a day, we can now accomplish in an hour."That's an 8x improvement in productivity for specific workflows — the kind of measurable return on investment that enterprises increasingly demand from AI implementations. Mike Krieger, Anthropic's chief product officer and Instagram co-founder, recently noted that companies have moved past "AI FOMO" to requiring concrete success metrics.Design platform Canva plans to integrate Skills into its own AI agent workflows. "Canva plans to leverage Skills to customize agents and expand what they can do," said Anwar Haneef, general manager and head of ecosystem at Canva in a statement. "This unlocks new ways to bring Canva deeper into agentic workflows—helping teams capture their unique context and create stunning, high-quality designs effortlessly."Cloud storage provider Box sees Skills as a way to make corporate content repositories more actionable. "Skills teaches Claude how to work with Box content," said Yashodha Bhavnani, head of AI at Box. "Users can transform stored files into PowerPoint presentations, Excel spreadsheets, and Word documents that follow their organization's standards—saving hours of effort."The enterprise security question: Who controls which AI skills employees can use?For enterprise IT departments, Skills raise important questions about governance and control—particularly since the feature allows AI to execute arbitrary code in sandboxed environments. Anthropic has built administrative controls that allow enterprise customers to manage access at the organizational level."Enterprise admins control access to the Skills capability via admin settings, where they can enable or disable access and monitor usage patterns," Murag said. "Once enabled at the organizational level, individual users still need to opt in."That two-layer consent model — organizational enablement plus individual opt-in — reflects lessons learned from previous enterprise AI deployments where blanket rollouts created compliance concerns. However, Anthropic's governance tools appear more limited than some enterprise customers might expect. The company doesn't currently offer granular controls over which specific skills employees can use, or detailed audit trails of custom skill content.Organizations concerned about data security should note that Skills require Claude's code execution environment, which runs in isolated containers. Anthropic advises users to "stick to trusted sources" when installing skills and provides security documentation, but the company acknowledges this is an inherently higher-risk capability than traditional AI interactions.From API to no-code: How Anthropic is making Skills accessible to everyoneAnthropic is taking several approaches to make Skills accessible to users with varying technical sophistication. For non-technical users on Claude.ai, the company provides a "skill-creator" skill that interactively guides users through building new skills by asking questions about their workflow, then automatically generating the folder structure and documentation.Developers working with Anthropic's API get programmatic control through a new /skills endpoint and can manage skill versions through the Claude Console web interface. The feature requires enabling the Code Execution Tool beta in API requests. For Claude Code users, skills can be installed via plugins from the anthropics/skills GitHub marketplace, and teams can share skills through version control systems."Skills are included in Max, Pro, Teams, and Enterprise plans at no additional cost," Murag confirmed. "API usage follows standard API pricing," meaning organizations pay only for the tokens consumed during skill execution, not for the skills themselves.Anthropic provides several pre-built skills for common business tasks, including professional generation of Excel spreadsheets with formulas, PowerPoint presentations, Word documents, and fillable PDFs. These Anthropic-created skills will remain free.Why the Skills launch matters in the AI coding wars with OpenAIThe Skills announcement arrives during a pivotal moment in Anthropic's competition with OpenAI, particularly around AI-assisted software development. Just one day before releasing Skills, Anthropic launched Claude Haiku 4.5, a smaller and cheaper model that nonetheless matches the coding performance of Claude Sonnet 4 — which was state-of-the-art when released just five months ago.That rapid improvement curve reflects the breakneck pace of AI development, where today's frontier capabilities become tomorrow's commodity offerings. OpenAI has been pushing hard on coding tools as well, recently upgrading its Codex platform with GPT-5 and expanding GitHub Copilot's capabilities.Anthropic's revenue trajectory — potentially reaching $26 billion in 2026 from an estimated $9 billion by year-end 2025 — suggests the company is successfully converting enterprise interest into paying customers. The timing also follows Salesforce's announcement this week that it's deepening AI partnerships with both OpenAI and Anthropic to power its Agentforce platform, signaling that enterprises are adopting a multi-vendor approach rather than standardizing on a single provider.Skills addresses a real pain point: the "prompt engineering" problem where effective AI usage depends on individual employees crafting elaborate instructions for routine tasks, with no way to share that expertise across teams. Skills transforms implicit knowledge into explicit, shareable assets. For startups and developers, the feature could accelerate product development significantly — adding sophisticated document generation capabilities that previously required dedicated engineering teams and weeks of development.The composability aspect hints at a future where organizations build libraries of specialized skills that can be mixed and matched for increasingly complex workflows. A pharmaceutical company might develop skills for regulatory compliance, clinical trial analysis, molecular modeling, and patient data privacy that work together seamlessly — creating a customized AI assistant with deep domain expertise across multiple specialties.Anthropic indicates it's working on simplified skill creation workflows and enterprise-wide deployment capabilities to make it easier for organizations to distribute skills across large teams. As the feature rolls out to Anthropic's more than 300,000 business customers, the true test will be whether organizations find Skills substantively more useful than existing customization approaches.For now, Skills offers Anthropic's clearest articulation yet of its vision for AI agents: not generalists that try to do everything reasonably well, but intelligent systems that know when to access specialized expertise and can coordinate multiple domains of knowledge to accomplish complex tasks. If that vision catches on, the question won't be whether your company uses AI — it will be whether your AI knows how your company actually works.
