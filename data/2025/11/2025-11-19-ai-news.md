# AI News for 2025-11-19 (America/Los_Angeles)

Collected 29 article(s).

- [What jobs will be most affected by AI? - Brookings](https://news.google.com/rss/articles/CBMifkFVX3lxTE1BMVlOZG5RdnYxYjNqY19QM0o3cUJqc0hGaGt1UTlSbFM1NjZpdUFTVzB4aVFIRk4zX2hoLUlQd3d3bE02TkJMblpCalZDREp2R2dfSmV6LVVVbmhlTUsteHQycENJZ1FDX3hVM3lYUVdkZklaZzhhX2hJMm1NQQ?oc=5) — 21:34 · Google News (AI)
  > What jobs will be most affected by AI?  Brookings
- [How the EU botched its attempt to regulate AI - Financial Times](https://news.google.com/rss/articles/CBMicEFVX3lxTFBja1dSRVZjcmVhVjJKcVhROHA0clhUamtKckg3MDdXYVdoS3BZT3NlRU1JNk5QYVpSak4xYnhiLWRpZWQ4UTctM0tRSnpjRU9Ba0ZWM3BmbTl6RWU1VWVYNFdhdU55Yk4tYkJnZHBlVV8?oc=5) — 21:00 · Google News (AI)
  > How the EU botched its attempt to regulate AI  Financial Times
- [AI borrowing binge prompts investors to back away from corporate bonds - Reuters](https://news.google.com/rss/articles/CBMif0FVX3lxTE94V0VCRXI1cU5ZUWRENVpFLWF6VU9qRmJ3TGJpYnlLZE91cXNTUHNsZ3YtS0hLdVBtWFNOc0hvUnpxYldRMklXUm9VQmpmb3BxcVFYYzdXeS1EaXkxcXh4Rnh5LVR0cHRxeVlLQjZNX256azBVa2RMMVB2M3RUVUE?oc=5) — 21:00 · Google News (AI)
  > AI borrowing binge prompts investors to back away from corporate bonds  Reuters
- [AI Threatens to Spoil Poland’s $1 Trillion Economic Party - Bloomberg.com](https://news.google.com/rss/articles/CBMiqgFBVV95cUxNbjdGTEtCLTdwcWJseDFScV9IaHF0S3p3U1EzdWJPTlJ0RUpJelRZM2Ftdi1pZFFHX09EQzRhajI5OTVZU3BLZnk2enFLWEFBb3lUTUlBd0t2dnZic05CN25ReFEwNGYwaXk2dFdsdU9kSXhydlBpdlkxMUx3TDRPSXRzTHpJQS1VTWk4bElTRDhJQnphNklHeHBfSDhxY0d5M0RjOWhyZEdhQQ?oc=5) — 21:00 · Google News (AI)
  > AI Threatens to Spoil Poland’s $1 Trillion Economic Party  Bloomberg.com
- [Ai2’s Olmo 3 family challenges Qwen and Llama with efficient, open reasoning and customization](https://venturebeat.com/ai/ai2s-olmo-3-family-challenges-qwen-and-llama-with-efficient-open-reasoning) — 21:00 · VentureBeat AI
  > The Allen Institute for AI (Ai2) hopes to take advantage of an increased demand for customized models and enterprises seeking more transparency from AI models with its latest release.Ai2 made the latest addition to its Olmo family of large language models available to organizations, continuing to focus on openness and customization. Olmo 3 has a longer context window, more reasoning traces and is better at coding than its previous iteration. This latest version, like the other Olmo releases, is open-sourced under the Apache 2.0 license. Enterprises will have complete transparency into and control over the training data and checkpointing. Ai2 will release three versions of Olmo 3:Olmo 3- Think in both 7B and 32B are considered the flagship reasoning models for advanced researchOlmo 3- Base also in both parameters, which is ideal for programming, comprehension, math and long-context reasoning. Ai2 said this version is “ideal for continued pre-training or fine-tuningOlmo 3-Instruct in 7B that is optimized for instruction following, multi-turn dialogue and tool useThe company said Olmo 3- Think is the “first-ever fully open 32B thinking model that generates explicit reasoning-chain-style content.” Olmo-3 Think also has a long context window of 65,000 tokens, perfect for longer-running agentic projects or reasoning over longer documents. Noah Smith, Ai2’s senior director of NLP research, told VentureBeat in an interview that many of its customers, from regulated enterprises to research institutions, want to use models that give them assurance about what went into the training. “The releases from our friends in the tech world are very cool and super exciting, but there are a lot of people for whom data privacy control over what goes into the model, how the models train and other constraints on how the model can be used as front of mind,” said Smith. Developers can access the models on Hugging Face and the Ai2 Playground. Transparency and customizationSmith said models like Olmo 3, which the company believes any organization using its models has to have control over and mold in the way that best works for them.“We don't believe in one-size-fits-all solutions,” Smith said. It's a known thing in the world of machine learning that if you try and build a model that solves all the problems, it ends up not being really the best model for any one problem. There aren't formal proofs of that, but it's a thing that old timers like me have kind of observed.”He added that models with the ability to specialize “are maybe not as flash as getting high scores on math exams” but offer more flexibility for enterprises. Olmo 3 allows enterprises to essentially retrain the model by adding to the data mix it learns from. The idea is that businesses can bring in their proprietary sources to guide the model in answering specific company queries. To help enterprises during this process, Ai2 added checkpoints from every major training phase. Demand for model customization has grown as enterprises that cannot build their own LLMs want to create company-specific or industry-focused models. Startups like Arcee have begun offering enterprise-focused, customizable small models. Models like Olmo 3, Smith said, also give enterprises more confidence in the technology. Since Olmo 3 provides the training data, Smith said enterprises can trust that the model did not ingest anything it shouldn’t have.Ai2 has always claimed to be committed to greater transparency, even launching a tool called OlmoTrace in April that can track a model’s output directly back to the original training data. The company releases open-sourced models and posts its code to repositories like GitHub for anyone to use. Competitors like Google and OpenAI have faced criticism from developers over moves that hid raw reasoning tokens and chose to summarize reasoning, claiming that they now resort to “debugging blind” without transparency. Ai2 pretrained Olmo 3 on the six-trillion-token OpenAI dataset, Dolma 3. The dataset encompasses web data, scientific literature and code. Smith said they optimized Olmo 3 for code, compared to the focus on math for Olmo 2. How it stacks upAi2 claims that the Olmo 3 family of models represents a significant leap for truly open-source models, at least for open-source LLMs developed outside China. The base Olmo 3 model trained “with roughly 2.5x greater compute efficiency as measured by GPU-hours per token,” meaning it consumed less energy during pre-training and costs less.The company said the Olmo 3 models outperformed other open models, such as Marin from Stanford, LLM360’s K2, and Apertus, though Ai2 did not provide figures for the benchmark testing. “Of note, Olmo 3-Think (32B) is the strongest fully open reasoning model, narrowing the gap to the best open-weight models of similar scale, such as the Qwen 3-32B-Thinking series of models across our suite of reasoning benchmarks, all while being trained on 6x fewer tokens,” Ai2 said in a press release. The company added that Olmo 3-Instruct performed better than Qwen 2.5, Gemma 3 and Llama 3.1.
- [Cal State says staff AI use ‘resulted in errors’ in legal filing - EdSource](https://news.google.com/rss/articles/CBMidkFVX3lxTE5sd3VVRmtoM1RJc2dlcXl2V1BnaXZFdHY2VkprR2g1SFRfNnVhLXZqNnR1Y0l4S2JSTktUM05Dem1TaUxPd3lXZ2tlU3lNQlFRVElva2p0TDZLOXJLMUR6MXlIR3NPWjRnMGZ3ZGZ3YW44YWtSaGc?oc=5) — 19:47 · Google News (AI)
  > Cal State says staff AI use ‘resulted in errors’ in legal filing  EdSource
- [In the A.I. Race, Chinese Talent Still Drives American Research - The New York Times](https://news.google.com/rss/articles/CBMigwFBVV95cUxPb2sxOVgtOS1uRW1lWVFCZkJld1FySDloZ3IzbVFWZ3h1Ym44NWd3UDFKY3I2aXB3ZFQ4MnFHcFZDa01oVDBkOFMteFhjblB6SDI2eUpwUFQxY0RhU3IteDFQODVnWm5FU1JRUTVhcDZRV0p5M1FEeXpTZjdTVEl0M2dMNA?oc=5) — 19:02 · Google News (AI)
  > In the A.I. Race, Chinese Talent Still Drives American Research  The New York Times
- [How JPMorgan's embrace of AI could change banking for us all - WBUR](https://news.google.com/rss/articles/CBMigwFBVV95cUxNNWdtWk9YMkNlYmtNU3ZkTHl0V0dEZzhXWmNOd1JUalZWYW1aTDdHSFN2SWJYM0Z2NG50aVFMa04ycGZrUHZkNThkbjNWa3ZYSFRKRklDWjNYWnUzYTY1QVhwWHRCeTh3V3FQOURzUjYwc3hfYjNyYzZLZDE2ODEzaHVoSQ?oc=5) — 18:15 · Google News (AI)
  > How JPMorgan's embrace of AI could change banking for us all  WBUR
- [Oracle Was an AI Darling on Wall Street. Then Reality Set In. - The Wall Street Journal](https://news.google.com/rss/articles/CBMingNBVV95cUxOLXJuVWJTZEVnYnRLUkdqOUQwUnYwTEVpTWtSNFVmUV9aVFVOaVJsYXRFSVlOZ0UyZlJSd252b3ppR08wOU1Rdl9PdnFNWkNIVFdBdnoyWDR4a3RDRVc0c2dLaWlxeFQ5ZmhDbDB2U1FHRFpWYWFnbmt3SXBFSkwzQ092c25mdzFYOFlieE9mbFl4T1d4Q2ptM093QjVkWE9aUm5XQl9GZjZFTUFYRGdlLVhSV0E0aFBWeW8xcTBhQlpxbHV3QjBsMHpLeUwyTmRhbGhnSHp5elF1c2MtQ2ZhcXQzTm9XWjY4eWJ2SXNaZ3dmb3FUSEVPQzd4Vk05VXRNRmx1SXRTSzBWVzE4UDJQbzlmbExVSzFxYm11Sk5OelJwbE1NSnJ5b0pBNmNrNDNFX1dQUU5Td0x0REFseGNxRG5zX2lUY0I2eWRDZEw5VllkSksxeTRqUHJJdEloN2M1UGxwZW9lWEx1OW04eWV4bDFvT0o4LUxBaDJmcndlSjlXdUZheHNOX3VXbTQxckRJeDNFWENsVVpSQ21PWmc?oc=5) — 18:00 · Google News (AI)
  > Oracle Was an AI Darling on Wall Street. Then Reality Set In.  The Wall Street Journal
- [European Commission proposes significant reforms to GDPR, AI Act - IAPP](https://news.google.com/rss/articles/CBMikAFBVV95cUxOaWVVWWNIbDVySk5IbmRoTHdKbGdRTUJTc1NpMFpfT2V4VmJXdjVpVkV5TXZ6QWVGbFQxY0M0VnBiVm81THFUNi1KRnEtcUwybVp1aFdzcFdzTHduNks4RWNYc1pfMXljNEJPODlOZ3d3WXVqb0ZXcWRzOWxPUG9kdG1aNTZHV2JxajRrdTdJYkM?oc=5) — 17:52 · Google News (AI)
  > European Commission proposes significant reforms to GDPR, AI Act  IAPP
- [Trump Takes Aim at State AI Laws in Draft Executive Order - WIRED](https://news.google.com/rss/articles/CBMijgFBVV95cUxOaHpaRW1FbTdROGl5d1hneUh0dDYzS25KYjFoakxjX3dleC1GMlVPSk9mRmY3eFBIQjRad3lxbWFUTS1Ga3VGNDVjYktISDQ4ZGp6Q2lPdE5NeEt4ZU1JakowZkExaXdfUE9ZS2VEMUxTNnZhNlo1UHNWRzJyOGNCMmJDamd4dlhTVjBrNUdB?oc=5) — 17:50 · Google News (AI)
  > Trump Takes Aim at State AI Laws in Draft Executive Order  WIRED
- [Major music labels strike licensing deals with AI streaming startup Klay, Bloomberg News reports - Reuters](https://news.google.com/rss/articles/CBMiywFBVV95cUxPSk1Da2RPTFZfMGQ1dmpxczdVNHNNcnBSeDV5Ym9qdlVMQnE4ZkwzYVM3R1A3Xy1Fa1RCSlpGWEZZbEttdVJ6NXd6OGJaLTl3QlhBZFJMRDB1Q0NFeVNVR2pkY2RvUDZrYjNlSkIwUzZmRE9rcXZRendhVEZVX3YyQjVXZUNQYzQtdnRlTE9GaWJHcGRvdS11OUhDUzVWeXAyNEEyVWJETE9RTGFrSFFHSTFhTWhSOEdzSkZGY1ZhN1kzQnJXWDZxWUlrQQ?oc=5) — 17:42 · Google News (AI)
  > Major music labels strike licensing deals with AI streaming startup Klay, Bloomberg News reports  Reuters
- [Nvidia CEO Jensen Huang rejects talk of AI bubble: 'We see something very different' - CNBC](https://news.google.com/rss/articles/CBMiogFBVV95cUxQTGQxbGU3REVUajZRWGFNMjZpbTJjY1lCSUhBMlg3X3NOejZHOFZza3VZMTVZZjlHTmEtSjVBVEFuYWV1YS1zM2h1TEZaLW5ycGN0clk2czEyT1hUWFVCYmhpMGhiVVBGeFpvN1ZqQ1dfZU9qam9jNVROems3SmNuWTc3T2h5c3JrNWJISGh2Zmk2ZTByVlV6bmNrUm1UOXFUZFE?oc=5) — 16:58 · Google News (AI)
  > Nvidia CEO Jensen Huang rejects talk of AI bubble: 'We see something very different'  CNBC
- [U launches ChatGPT Edu, a university-centered generative AI tool for campus use - The University of Utah](https://news.google.com/rss/articles/CBMitwFBVV95cUxQU2hrU0JoU3VzQ3RBOEk5TmNsbTVXb3ZoWXhEQXltaVYtX2JwamZ6c2M3WVo5VUNHUTZ5MEhsd0pVdV9rTGc3eDNNZTJlV0E1UEhEajF5WmhQVXNCSGlXZUFqc2xXdEtIeW53QXdxNHN3Nkxna0pJUVVGcWwwSGlxRDZQQTlzNkx3QUtEMmVzcHF3bXM1dHQ5UmRaR0JNWmVvMU8wbnZ0STYyRmc0LVdScUpkVGxXa3c?oc=5) — 16:57 · Google News (AI)
  > U launches ChatGPT Edu, a university-centered generative AI tool for campus use  The University of Utah
- [Trump considering executive order to preempt state AI laws - Reuters](https://news.google.com/rss/articles/CBMiqwFBVV95cUxON3FXYmJYREFwTkt0eEpKSUZUT1NJOTJ2TEhxN0pxbFBzcEZSUlRBamRPZlV1bFRnTmJySjkwcFgyT1ZKOVJSYzRsYWtRb2VhZUtJaXRWSFVhOUZHcEd4cUdaSWotQ1RUS1RsbE9UYmdBQ2VFajBpQ3dJc1MwVk9jT1BfN05lelhrblBfYkRtY0M0WHp4dXB4ZGV0T003X1dLOU5LRFg3SW1SQ28?oc=5) — 16:10 · Google News (AI)
  > Trump considering executive order to preempt state AI laws  Reuters
- [Trump administration drafts an executive order to challenge state AI laws - NBC News](https://news.google.com/rss/articles/CBMixAFBVV95cUxObUxfR2Q3ZmdlMXpRQ3ZlcG5ycjA4Z09ydXAtcWljZFp1cVlXZjdYTXdCdHE3bzJvM09vbmtEendnbFc0VUxFYU1XMlBmdzcyc3hTeTJySHpERHlUVjdvWWFzVFQyNVlIOXZNMk9DaUxpM2dqTHk2RGQ4c0pBUkdyUmxVZHVTRzRoQ3NETllwUTJDXy10VEl1ZWNoNzg4Q3RFLVhSbWZnNlZkQXgzNXk3d3V2S1d6SFcwVHRFNVRtRFFiSURO0gFWQVVfeXFMTVBlYWpwbVZWQll6V2VzenpEQ003cE1Od2pucEhXRmdlUFR0am43SkFzbHowb05fTWNoSlI5T21Pa0NyN2xyLVdaT2hHelNNOVBOU0dzbVE?oc=5) — 16:09 · Google News (AI)
  > Trump administration drafts an executive order to challenge state AI laws  NBC News
- [White House prepares executive order to block state AI laws - Politico](https://news.google.com/rss/articles/CBMirgFBVV95cUxOck1ZRXd3OUhfWFdKN3pwVWRwRzNhVkJXTDBOU1FyUFV4RE12RUdacWd0cHgyX3dINzB1aEFhcHYyRENwT0pKNVh6ZGUtUmVzMU95U28wTFI5cGMwdGZZWWgwdU1JTmo3MzdXVGFINTY1Z2NsZG1KYkk1TGQ5QU5nOVlxNXRZckNiN3ZvdFpXNDQ1WFE4OVVoSUxWdENWWTN1SlVNTXI0bWVRei1NckE?oc=5) — 15:36 · Google News (AI)
  > White House prepares executive order to block state AI laws  Politico
- [Teachers and parents weigh benefits and risks of artificial intelligence in schools - PBS](https://news.google.com/rss/articles/CBMiuAFBVV95cUxNUVlPWHBqMTl4N0UzZ20wTW85UWdFb0VHYWtpdVdhR2JzTW96QWtJanFpeGczVTByX3lISUE1V1BCYkFuamVaOW9yZW9BUlJTYkZmWUVHSDA3ZXphQlBWakF3OUp5cHljbHJJU3dmNkZRTnpqTWszNnRjLTRfSGx1ZU9waERIMVhDelY2Y0ttTkw2Z2lOSFV3bEwzVk1HUG9CYzZkRTVpQWZPVlU1VkpsMUdwOEFqVGZQ?oc=5) — 15:30 · Google News (AI)
  > Teachers and parents weigh benefits and risks of artificial intelligence in schools  PBS
- [Yann LeCun, a Pioneering A.I. Scientist, Leaves Meta - The New York Times](https://news.google.com/rss/articles/CBMihgFBVV95cUxQREl4ME9WTHRrcUExZGdfNVAyNFpMbU5XVWNmTWxrTXU3WmVkRm11TkJLS0FoOVl3OXptRXd6X2ZZYkRjTENtdmY1bng4S0R6ekRhQnl0dUxueTNZRGJLRTBHcV8zWnFVNElSTHhvNTAwcFpWOUk3dmduQTdVUlhyS21pY2E4QQ?oc=5) — 15:12 · Google News (AI)
  > Yann LeCun, a Pioneering A.I. Scientist, Leaves Meta  The New York Times
- [Exclusive | U.S. Approves Deal to Sell AI Chips to Middle East - The Wall Street Journal](https://news.google.com/rss/articles/CBMilANBVV95cUxOM1BNSm5WUFVBU1NBT2ZfWi1lNU03eEd1RGkwNWRBQVB4eEFaNko4aGtRZTNfU2MtN1pkSGJZTUg0ZWRiSWhUYWk4ZGV0REVLMTJRT3ZrdTJHazUtSjJKZDA3NUJJOE9QNFFEMTRuYk1USGFXa3RnaXJnakd0VzdsUTA3Y3BCRzgyam56SEd0MmZQY0JyN29PVjlEVlRTVGE3a0lNVEl2U1JfcGVsdjVLa0JoeF9iX0M1YU1tczRocW5JTk1FNDR6QlEtLXVuN0VtV1BVaU5HbzJDVXBTam9pZmRBMUlpNXZhTWNLSHZuaXA4dFl1QXRza3FyN0lraEJsNVRMREpFY3doeTRBRW0wSVFBWjRKakw0clR5RWNldWVueGEzX3phTS1mRWVxR0thdjMzTXg0MTFDaEhmNVNjc1NMVi0ybGdRSjBhNWp1a2dPUVR5TE1sUDNPWV9TU2w1U1gtVHpQTWhDR1VBY0p6RXZCVTYtRWh6eFVkNEJ3VnNsS081YmticEx2Ylk0SERLdThudw?oc=5) — 14:53 · Google News (AI)
  > Exclusive | U.S. Approves Deal to Sell AI Chips to Middle East  The Wall Street Journal
- [Moratoriums and Federal Preemption of State Artificial Intelligence Laws Pose Serious Risks - Center for American Progress](https://news.google.com/rss/articles/CBMizgFBVV95cUxNTkg4WThkQk0zanp5TjMwQU5jWEhuaGdPZkpHNjFsR0FpMjBqcncxR0tadVhUeFQ1OUFsLWprWVhfbnZpSDNkS0lXRlZmemk3bjVRWWFteEFvX3B6UXBSNUtqdkctd3NpRURlSUViZ3FjdlVEa1kwUzZ0QlMwQXJIQVlMdjBvRGFVNWlHZlBFbnpTbk9sTm9rMWFyVXBLNWJVZ3lZOEF0YUhOZDhGclhoZFM3OWRveUZHX2dLOU5wWmhXcGdCNjE0UEJLUGViUQ?oc=5) — 14:04 · Google News (AI)
  > Moratoriums and Federal Preemption of State Artificial Intelligence Laws Pose Serious Risks  Center for American Progress
- [Meta chief AI scientist Yann LeCun is leaving to create his own startup - CNBC](https://news.google.com/rss/articles/CBMimwFBVV95cUxPTGdWSmlnTFk0RjBMb2hrU3pocWwtZUNuZW1VWXhFTnlhVmJ1U29YT19HOUxsaDFqekNWS0ZhdkhOWnkwdldibnFlTEw0UTJPdVJHNzNSM0RSZDR0dXZwOFFaTkVza3RVQU5veGlhcTBhNTVlTjJPSHd0SGQ0QVVub3p5RFJDNXpPSDNrMTZyWUM5UF9TSTcyd0EwY9IBoAFBVV95cUxNNU1fSjRLVkJ2UXRVa1RXQmJGVDNkNGo5cGZSLTctUW5FVHY2M2dGWWljTWsyWm8waV9JTEVzeGkyM0o1VkxnbVNLR2JmeFBfaV9ydUF6WkhpZmdNOU9TVnRWXzg2cmdVdkJYZUJtSUFqako5Rzg1S2ZZSXQ3WVVDMDgtcVhOM3Zmc1Fvd0ZIX3gyY3VweTF0Um5qZURlUDA0?oc=5) — 13:31 · Google News (AI)
  > Meta chief AI scientist Yann LeCun is leaving to create his own startup  CNBC
- [NVIDIA Announces Financial Results for Third Quarter Fiscal 2026 - NVIDIA Newsroom](https://news.google.com/rss/articles/CBMioAFBVV95cUxOR1BQNkZyZnMwM0Z3OWN1VHU0eXZEMHVsMDhNNnYyc1JCQTB5VHB4Z0tUMWp3eXdlaHBESXRSM202TV9PMWIxUEl3bV9oYmNqQWM4S0h3em0wYTJ6X2V2b3NmNGh5cllhRlFXMTBNczY4RVFkSGZFV3dzdnZEU2ZESmVKMmlCVWVuWXNpNXZ6eldZUmFsRk9sNGgtZTB1clFo?oc=5) — 13:11 · Google News (AI)
  > NVIDIA Announces Financial Results for Third Quarter Fiscal 2026  NVIDIA Newsroom
- [OpenAI debuts GPT‑5.1-Codex-Max coding model and it already completed a 24-hour task internally](https://venturebeat.com/ai/openai-debuts-gpt-5-1-codex-max-coding-model-and-it-already-completed-a-24) — 11:26 · VentureBeat AI
  > OpenAI has introduced GPT‑5.1-Codex-Max, a new frontier agentic coding model now available in its Codex developer environment. The release marks a significant step forward in AI-assisted software engineering, offering improved long-horizon reasoning, efficiency, and real-time interactive capabilities. GPT‑5.1-Codex-Max will now replace GPT‑5.1-Codex as the default model across Codex-integrated surfaces.The new model is designed to serve as a persistent, high-context software development agent, capable of managing complex refactors, debugging workflows, and project-scale tasks across multiple context windows.It comes on the heels of Google releasing its powerful new Gemini 3 Pro model yesterday, yet still outperforms or matches it on key coding benchmarks: On SWE-Bench Verified, GPT‑5.1-Codex-Max achieved 77.9% accuracy at extra-high reasoning effort, edging past Gemini 3 Pro’s 76.2%. It also led on Terminal-Bench 2.0, with 58.1% accuracy versus Gemini’s 54.2%, and matched Gemini’s score of 2,439 on LiveCodeBench Pro, a competitive coding Elo benchmark.When measured against Gemini 3 Pro’s most advanced configuration — its Deep Thinking model — Codex-Max holds a slight edge in agentic coding benchmarks, as well. Performance Benchmarks: Incremental Gains Across Key TasksGPT‑5.1-Codex-Max demonstrates measurable improvements over GPT‑5.1-Codex across a range of standard software engineering benchmarks. On SWE-Lancer IC SWE, it achieved 79.9% accuracy, a significant increase from GPT‑5.1-Codex’s 66.3%. In SWE-Bench Verified (n=500), it reached 77.9% accuracy at extra-high reasoning effort, outperforming GPT‑5.1-Codex’s 73.7%.Performance on Terminal Bench 2.0 (n=89) showed more modest improvements, with GPT‑5.1-Codex-Max achieving 58.1% accuracy compared to 52.8% for GPT‑5.1-Codex. All evaluations were run with compaction and extra-high reasoning effort enabled.These results indicate that the new model offers a higher ceiling on both benchmarked correctness and real-world usability under extended reasoning loads.Technical Architecture: Long-Horizon Reasoning via CompactionA major architectural improvement in GPT‑5.1-Codex-Max is its ability to reason effectively over extended input-output sessions using a mechanism called compaction. This enables the model to retain key contextual information while discarding irrelevant details as it nears its context window limit — effectively allowing for continuous work across millions of tokens without performance degradation.The model has been internally observed to complete tasks lasting more than 24 hours, including multi-step refactors, test-driven iteration, and autonomous debugging.Compaction also improves token efficiency. At medium reasoning effort, GPT‑5.1-Codex-Max used approximately 30% fewer thinking tokens than GPT‑5.1-Codex for comparable or better accuracy, which has implications for both cost and latency.Platform Integration and Use CasesGPT‑5.1-Codex-Max is currently available across multiple Codex-based environments, which refer to OpenAI’s own integrated tools and interfaces built specifically for code-focused AI agents. These include:Codex CLI, OpenAI’s official command-line tool (@openai/codex), where GPT‑5.1-Codex-Max is already live.IDE extensions, likely developed or maintained by OpenAI, though no specific third-party IDE integrations were named.Interactive coding environments, such as those used to demonstrate frontend simulation apps like CartPole or Snell’s Law Explorer.Internal code review tooling, used by OpenAI’s engineering teams.For now, GPT‑5.1-Codex-Max is not yet available via public API, though OpenAI states this is coming soon. Users who wish to work with the model in terminal environments today can do so by installing and using the Codex CLI.It is not currently confirmed whether or how the model will integrate into third-party IDEs unless they are built on top of the CLI or future API.The model is capable of interacting with live tools and simulations. Examples shown in the release include:An interactive CartPole policy gradient simulator, which visualizes reinforcement learning training and activations.A Snell’s Law optics explorer, supporting dynamic ray tracing across refractive indices.These interfaces exemplify the model’s ability to reason in real time while maintaining an interactive development session — effectively bridging computation, visualization, and implementation within a single loop.Cybersecurity and Safety ConstraintsWhile GPT‑5.1-Codex-Max does not meet OpenAI’s “High” capability threshold for cybersecurity under its Preparedness Framework, it is currently the most capable cybersecurity model OpenAI has deployed. It supports use cases such as automated vulnerability detection and remediation, but with strict sandboxing and disabled network access by default.OpenAI reports no increase in scaled malicious use but has introduced enhanced monitoring systems, including activity routing and disruption mechanisms for suspicious behavior. Codex remains isolated to a local workspace unless developers opt-in to broader access, mitigating risks like prompt injection from untrusted content.Deployment Context and Developer UsageGPT‑5.1-Codex-Max is currently available to users on ChatGPT Plus, Pro, Business, Edu, and Enterprise plans. It will also become the new default in Codex-based environments, replacing GPT‑5.1-Codex, which was a more general-purpose model.OpenAI states that 95% of its internal engineers use Codex weekly, and since adoption, these engineers have shipped ~70% more pull requests on average — highlighting the tool’s impact on internal development velocity.Despite its autonomy and persistence, OpenAI stresses that Codex-Max should be treated as a coding assistant, not a replacement for human review. The model produces terminal logs, test citations, and tool call outputs to support transparency in generated code.OutlookGPT‑5.1-Codex-Max represents a significant evolution in OpenAI’s strategy toward agentic development tools, offering greater reasoning depth, token efficiency, and interactive capabilities across software engineering tasks. By extending its context management and compaction strategies, the model is positioned to handle tasks at the scale of full repositories, rather than individual files or snippets.With continued emphasis on agentic workflows, secure sandboxes, and real-world evaluation metrics, Codex-Max sets the stage for the next generation of AI-assisted programming environments — while underscoring the importance of oversight in increasingly autonomous systems.
- [The Google Search of AI agents? Fetch launches ASI:One and Business tier for new era of non-human web](https://venturebeat.com/ai/the-google-search-of-ai-agents-fetch-launches-asi-one-and-business-tier-for) — 09:57 · VentureBeat AI
  > Fetch AI, a startup founded and led by former DeepMind founding investor, Humayun Sheikh, on Wednesday announced the release of three interconnected products designed to provide the trust, coordination, and interoperability needed for large-scale AI agent ecosystems. The launch includes ASI:One, a personal-AI orchestration platform; Fetch Business, a verification and discovery portal for brand agents; and Agentverse, an open directory hosting more than two million agents. Together, the system positions Fetch as an infrastructure provider for what it calls the “Agentic Web”—a layer where consumer AIs and brand AIs collaborate to complete tasks instead of merely suggesting them.The company says the tools address a central limitation in current consumer AI: models can provide recommendations but cannot reliably execute multi-step actions that require coordination across businesses. Fetch’s approach centers on enabling agents from different organizations to interoperate securely, using verified identities and shared context to complete end-to-end workflows.“We’re creating the same foundation for agents that Google created for websites,” said Humayun Sheikh, Founder and CEO of Fetch AI, and an early investor in DeepMind, in a press release provided to VentureBeat. “Instead of just finding information, your personal AI coordinates with verified brand agents to get things done.”Fetch’s founding and DeepMind connection Fetch AI was founded in 2017 by Humayun Sheikh, an entrepreneur whose early investment in DeepMind helped support the company’s commercial development before its acquisition by Google. “I was one of the first five people at DeepMind and its first investor. My check was the first one in,” Sheikh said, reflecting on the period when advanced machine learning research was still largely inaccessible outside major technology companies.His early experience helped shape Fetch’s direction. “Even in 2013, it was clear to me that agentic systems were going to be the ones that worked. That’s where I focused—on the agentic web,” Sheikh noted. Fetch built on this thesis by developing infrastructure for autonomous software agents, focusing on verifiable identity, secure data exchange, and multi-agent coordination. Over the past several years, the company has expanded to a 70-person team across Cambridge and Menlo Park, raised approximately $60 million, and accumulated more than one million users interacting with its model—data that informed the design of the newly launched products.Sheikh added that his decision to bootstrap the company initially came directly from the proceeds of the DeepMind exit, noting in the interview that while the sale to Google was “a good exit,” he believed the team could have held out for a higher valuation. The early self-funding period allowed Fetch to begin work in 2015—well before transformer architectures went mainstream—on the hypothesis that agentic infrastructure would become foundational to applied AI.ASI:One is a platform for multi-agent orchestrationAt the core of the launch is ASI:One, a language model interface designed specifically for coordinating multiple agents rather than addressing isolated queries. Fetch describes it as an “intelligence layer” that handles context sharing, task routing, and preference modeling.The system stores user-level signals such as favored airlines, dietary constraints, budget ranges, loyalty program identifiers, and calendar availability. When a user requests a complex task — such as planning a trip with flights, hotels, and restaurant reservations — ASI:One retrieves those preferences and delegates work to the appropriate verified agents. The agents then return actionable outputs, including inventory and booking options, rather than generic recommendations.In practice, ASI:One functions as a workflow generator across organizational boundaries. By contrast with conventional LLM applications, which often rely on APIs or RAG techniques to surface information, ASI:One is built to coordinate autonomous agents that can complete transactions. Fetch notes that personalization improves over time as the model accumulates structured preference data.Sheikh emphasized the distinction between orchestrated execution and traditional AI output. “This isn’t searching for options separately and hoping they work together,” he said. “It’s orchestration.” He added that Fetch’s architecture is intentionally modular: “Our architecture is a mix of agentic and expert models. One large model isn’t enough — you need specialists. That’s why we built ASI1, tuned specifically for agentic systems.”The interview also revealed new details about ASI:One’s personalization systems: the platform uses multiple user-owned knowledge graphs to store preferences, travel history, social connections, and contextual constraints. These knowledge graphs are siloed per user and not co-mingled with any Fetch-operated data. Sheikh described this as a “deterministic backbone” that gives the personal AI a stable memory layer beyond the probabilistic output of a single large model.ASI:One launches in Beta today, with a broader release planned for early 2026. Fetch also offers ASI:One Mobile, released earlier this year, giving users access to the same agent-orchestration capabilities on iOS and Android. The mobile app connects directly to Agentverse and the user’s knowledge graphs, enabling on-the-go task execution and real-time interaction with registered agents.Fetch Business offers verified identity and brand controlTo enable reliable coordination between consumers and companies, Fetch is introducing a verification and discovery portal called Fetch Business. The platform allows organizations to verify their identity and claim an official Brand Agent handle — for example, @Hilton or @Nike — regardless of which tools they use to build the underlying agent.Fetch positions the product as an analogue to ICANN domain registration and SSL certificate systems for websites. Verified status is intended to protect consumers from interacting with counterfeit or untrusted agents, a problem the company describes as a major barrier to widespread agent adoption.The system includes low-code tools for small businesses to create agents in a few steps and connect real-time APIs such as inventory, booking systems, or CRM platforms. “With Fetch, you can create an agent in one minute. It gets a handle, like a Twitter username, and you can personalize it completely—even give it your social media permissions to post on your behalf,” Sheikh said. Once a brand claims its namespace, its agent becomes discoverable to consumer AIs and other agents inside Agentverse.The company has pre-reserved thousands of brand namespaces in anticipation of demand. Verification status persists across any platform that integrates with Agentverse, creating a portable identity layer for business agents.The interview highlighted that Fetch Business inherits web-trust primitives directly: domain owners verify their identity by inserting a short code snippet into their existing website backend, allowing the system to pass a cryptographic challenge and grant the agent an authenticity badge similar to a “blue check” for agent identities. Sheikh framed this as “reusing the trust layer the web already spent decades building.”Companies can begin claiming agents now at business.fetch.ai.Agentverse is an open directory of more yhan 2 million agentsThe final component of the release is Agentverse, an open directory and cloud platform that hosts agents and enables cross-ecosystem discoverability. Fetch states that millions of agents have already registered, spanning travel, retail, entertainment, food service, and enterprise categories.Agentverse provides metadata, capability descriptions, and routing logic that ASI:One uses to identify appropriate agents for specific tasks. It also supports secure communication and data exchange between agents. The company notes that the directory is platform-agnostic: agents built with any framework can join and interoperate.According to Sheikh, the lack of a discovery layer is one reason most AI agents see little or no usage. “Ninety percent of AI agents never get used because there’s no discovery layer,” he said. He framed the role of Agentverse in more technical terms: “Right now, if you build an agent, there’s no universal way for others to discover it. That’s what AgentVerse solves—it’s like DNS for agents.” He also described the system as an essential component of the emerging agent economy: “Fetch is building the Google of agents. Just like websites needed search, agents need discovery, trust, and interaction—Fetch provides all of that.”The interview further underscored that Agentverse is cloud-agnostic by design. Sheikh contrasted this with competing agent ecosystems tied to specific cloud providers, arguing that a universal registry is only viable if independent of proprietary cloud environments. He said the open architecture enables an LLM to query any agent “within one minute of deployment,” turning agent publication into a near-instantaneous process similar to registering a domain.Agentverse also integrates payment pathways, enabling agents to execute purchases using partners such as Visa, Skyfire, and supported stablecoins. Consumers can configure spending limits or require explicit approval for transactions.Industry context and implicationsFetch’s launch comes at a time when consumer AI platforms are exploring the shift from static chat interfaces toward autonomous agents capable of completing actions. However, most agent systems remain limited by siloed architectures, limited interoperability, and weak verification standards.Fetch positions its infrastructure as a response to these limitations by providing a cross-platform coordination layer, identity system, and directory service. The company argues that an agent ecosystem requires consistent verification mechanisms to ensure that consumers interact with authentic brand representatives rather than imitations. By establishing namespace control and portable trust indicators, Fetch Business aims to fill a gap similar to early web domain verification.At the same time, ASI:One attempts to centralize user preference data in a way that enables more efficient personalization and multi-agent coordination. This approach differs from generalist LLM applications, which often lack persistent preference architectures or direct access to brand-controlled agents.The interview also made clear that micropayments and digital transaction infrastructure are central to Fetch’s long-term vision. Sheikh referenced integrations with protocols such as Coinbase’s 402 and AP2, positioning these capabilities as essential for autonomous agents to complete end-to-end tasks that include financial execution.Fetch’s combined release of ASI:One, Fetch Business, and Agentverse introduces an interconnected stack designed to support large-scale deployment and usage of AI agents. The company frames the system as foundational infrastructure for an agentic ecosystem, where consumer AIs can coordinate with verified brand agents to complete tasks reliably and securely. The additions to its identity, discovery, and orchestration layers reflect Fetch’s long-standing thesis — rooted partly in lessons from DeepMind’s early development — that intelligence becomes meaningful only when paired with the capacity to act.
- [Scaling innovation in manufacturing with AI](https://www.technologyreview.com/2025/11/19/1128067/scaling-innovation-in-manufacturing-with-ai/) — 08:54 · MIT Technology Review (AI)
  > Manufacturing is getting a major system upgrade. As AI amplifies existing technologies—like digital twins, the cloud, edge computing, and the industrial internet of things (IIoT)—it is enabling factory operations teams to shift from reactive, isolated problem-solving to proactive, systemwide optimization. Digital twins—physically accurate virtual representations of a piece of equipment, a production line, a process,…
- [OpenCV founders launch AI video startup to take on OpenAI and Google](https://venturebeat.com/ai/opencv-founders-launch-ai-video-startup-to-take-on-openai-and-google) — 06:00 · VentureBeat AI
  > A new artificial intelligence startup founded by the creators of the world's most widely used computer vision library has emerged from stealth with technology that generates realistic human-centric videos up to five minutes long — a dramatic leap beyond the capabilities of rivals including OpenAI's Sora and Google's Veo.CraftStory, which launched Tuesday with $2 million in funding, is introducing Model 2.0, a video generation system that addresses one of the most significant limitations plaguing the nascent AI video industry: duration. While OpenAI's Sora 2 tops out at 25 seconds and most competing models generate clips of 10 seconds or less, CraftStory's system can produce continuous, coherent video performances that run as long as a typical YouTube tutorial or product demonstration.The breakthrough could unlock substantial commercial value for enterprises struggling to scale video production for training, marketing, and customer education — markets where brief AI-generated clips have proven inadequate despite their visual polish."If you really try to create a video with one of these video generation systems, you find that a lot of the times you want to implement a certain creative vision, and regardless of how detailed the instructions are, the systems basically ignore a part of your instructions," said Victor Erukhimov, CraftStory's founder and CEO, in an exclusive interview with VentureBeat. "We developed a system that can generate videos basically as long as you need them."How parallel processing solves the long-form video problemCraftStory's advance rests on what the company describes as a parallelized diffusion architecture — a fundamentally different approach to how AI models generate video compared to the sequential methods employed by most competitors.Traditional video generation models work by running diffusion algorithms on increasingly large three-dimensional volumes where time represents the third axis. To generate a longer video, these models require proportionally larger networks, more training data, and significantly more computational resources.CraftStory instead runs multiple smaller diffusion algorithms simultaneously across the entire duration of the video, with bidirectional constraints connecting them. "The latter part of the video can influence the former part of the video too," Erukhimov explained. "And this is pretty important, because if you do it one by one, then an artifact that appears in the first part propagates to the second one, and then it accumulates."Rather than generating eight seconds and then stitching on additional segments, CraftStory's system processes all five minutes concurrently through interconnected diffusion processes.Crucially, CraftStory trained its model on proprietary footage rather than relying solely on internet-scraped videos. The company hired studios to shoot actors using high-frame-rate camera systems that capture crisp detail even in fast-moving elements like fingers — avoiding the motion blur inherent in standard 30-frames-per-second YouTube clips."What we showed is that you don't need a lot of data and you don't need a lot of training budget to create high quality videos," Erukhimov said. "You just need high quality data."Model 2.0 currently operates as a video-to-video system: users upload a still image to animate and a "driving video" containing a person whose movements the AI will replicate. CraftStory provides preset driving videos shot with professional actors, who receive revenue shares when their motion data is used, or users can upload their own footage.The system generates 30-second clips at low resolution in approximately 15 minutes. An advanced lip-sync system synchronizes mouth movements to scripts or audio tracks, while gesture alignment algorithms ensure body language matches speech rhythm and emotional tone.Fighting a war chest battle with $2 million against billionsCraftStory's funding comes almost entirely from Andrew Filev, who sold his project management software company Wrike to Citrix for $2.25 billion in 2021 and now runs Zencoder, an AI coding company. The modest raise stands in stark contrast to the billions flowing into competing efforts — OpenAI has raised over $6 billion in its latest funding round alone.Erukhimov pushed back on the notion that massive capital is prerequisite for success. "I don't necessarily buy the thesis that compute is the path to success," he said. "It definitely helps if you have compute. But if you raise a billion dollars on a PowerPoint, in the end, no one is happy, neither the founders nor the investors."Filev defended the David-versus-Goliath approach. "When you invest in startups, you're fundamentally betting on people," he said in an interview with VentureBeat. "To paraphrase Margaret Mead: never underestimate what a small group of thoughtful, committed engineers and scientists can build."He argued that CraftStory benefits from a focused strategy. "The big labs are in an arms race to build general-purpose video foundation models," Filev said. "CraftStory is riding that wave and going very deep into a specific format: long-form, engaging, human-centric video."Why computer vision expertise matters in generative AI videoErukhimov's credibility stems from his deep roots in computer vision rather than the transformer architectures that have dominated recent AI advances. He was an early contributor to OpenCV — the Open Source Computer Vision Library that has become the de facto standard for computer vision applications, with over 84,000 stars on GitHub.When Intel reduced its support for OpenCV in the mid-2000s, Erukhimov co-founded Itseez with the explicit goal of maintaining and advancing the library. The company expanded OpenCV significantly and pivoted toward automotive safety systems before Intel acquired it in 2016.Filev said this background is precisely what makes Erukhimov well-positioned for video generation. "What people sometimes miss is that generative AI video isn't just about the generative part. It's about understanding motion, facial dynamics, temporal coherence, and how humans actually move," Filev said. "Victor has spent his career mastering exactly those problems."Enterprise focus targets training videos and product demosWhile much of the public excitement around AI video generation has centered on creative tools for consumers, CraftStory is pursuing a decidedly enterprise-focused strategy."We are definitely thinking about B2B more than consumer," Erukhimov said. "We're thinking about companies, specifically software companies, being able to make cool training videos and product videos and launch videos."The logic is straightforward: corporate training, product tutorials, and customer education videos often run several minutes and require consistent quality throughout. A 10-second AI clip cannot effectively demonstrate how to use enterprise software or explain a complex product feature."If you need a longer-form video, then you should go with us," Erukhimov said. "We can create up to five minutes, consistent video, high quality."Filev echoed this assessment. "One huge gap in this market is the lack of models that can generate consistent videos over longer sequences — and that's extremely important for real-world use," he said. "If you're creating a commercial for your company, a 10-second video, no matter how good it looks, just isn't enough. You need 30 seconds, you need two minutes — you need more."The company anticipates cost savings for customers. Filev suggested that "a small business owner could create content in minutes that previously would have cost $20,000 and taken two months to produce."CraftStory is also courting creative agencies that produce video content for corporate clients, with the value proposition centered on cost and speed: agencies can record an actor on camera and transform that footage into a finished AI video, rather than managing expensive multi-day shoots.The next major development on CraftStory's roadmap is a text-to-video model that would allow users to generate long-form content directly from scripts. The team is also developing support for moving-camera scenarios, including the popular "walk-and-talk" format common in high-end advertising.Where CraftStory fits in a fragmented competitive landscapeCraftStory enters a crowded and rapidly evolving market. OpenAI's Sora 2, while not yet publicly available, has generated significant buzz. Google's Veo models are advancing quickly. Runway, Pika, and Stability AI all offer video generation tools with different capabilities.Erukhimov acknowledged the competitive pressure but emphasized that CraftStory serves a distinct niche focused on human-centric videos. He positioned rapid innovation and market capture as the company's primary strategy rather than relying on technical moats.Filev sees the market fragmenting into distinct layers, with large tech companies serving as "API providers of powerful, general-purpose generation models" while specialized players like CraftStory focus on specific use cases. "If the big players are building the engines, CraftStory is building the production studio and assembly line on top," he said.Model 2.0 is available now at app.craftstory.com/model-2.0, with the company offering early access to users and enterprises interested in testing the technology. Whether a lightly funded startup can capture meaningful market share against deep-pocketed incumbents remains uncertain, but Erukhimov is characteristically confident about the opportunity ahead."AI-generated video will soon become the primary way companies communicate their stories," he said.
- [The Download: de-censoring DeepSeek, and Gemini 3](https://www.technologyreview.com/2025/11/19/1128131/the-download-de-censoring-deepseek-and-gemini-3/) — 05:10 · MIT Technology Review (AI)
  > This is today’s edition of The Download, our weekday newsletter that provides a daily dose of what’s going on in the world of technology. Quantum physicists have shrunk and “de-censored” DeepSeek R1 The news: A group of quantum physicists at Spanish firm Multiverse Computing claims to have created a version of the powerful reasoning AI model DeepSeek…
- [Quantum physicists have shrunk and “de-censored” DeepSeek R1](https://www.technologyreview.com/2025/11/19/1128119/quantum-physicists-compress-and-deconsor-deepseekr1/) — 02:00 · MIT Technology Review (AI)
  > A group of quantum physicists claims to have created a version of the powerful reasoning AI model DeepSeek R1 that strips out the censorship built into the original by its Chinese creators.  The scientists at Multiverse Computing, a Spanish firm specializing in quantum-inspired AI techniques, created DeepSeek R1 Slim, a model that is 55% smaller…
